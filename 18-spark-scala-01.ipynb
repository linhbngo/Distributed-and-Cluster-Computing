{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Introduction to Spark In-memmory Computing via Spark Scala </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Spark is an implementation of the MapReduce programming paradigm that operates on in-memory data and allows data reuses across multiple computations.\n",
    "- Performance of Spark is significantly better than its predecessor, Hadoop MapReduce. \n",
    "- Spark's primary data abstraction is Resilient Distributed Dataset (RDD):\n",
    "    - Read-only, partitioned collection of records\n",
    "    - Created (aka written) through deterministic operations on data:\n",
    "        - Loading from stable storage\n",
    "        - Transforming from other RDDs\n",
    "        - Generating through coarse-grained operations such as map, join, filter ...\n",
    "    - Do not need to be materialized at all time and are recoverable via **data lineage**\n",
    "\n",
    "<img src=\"pictures/18/spark2_arch.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSH into CloudLab. \n",
    "\n",
    "```\n",
    "$ ssh node218.clemson.cloudlab.us\n",
    "```\n",
    "\n",
    "From inside the terminal, open Spark's interactive shell\n",
    "\n",
    "```\n",
    "$ spark-shell --master yarn --driver-memory 1G --executor-memory 10G --num-executors 10 --verbose\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting Started\n",
    "\n",
    "Spark stores data in memory. This memory space is represented by variable **sc** (SparkContext). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spark shell's prompt is **scala>**\n",
    "\n",
    "```\n",
    "scala> sc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```\n",
    "val textFile = sc.textFile(\"hdfs:///repository/gutenberg-shakespeare.txt\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type is `textFile`?\n",
    "\n",
    "```\n",
    "scala> print (textFile)\n",
    "scala> printf (textFile)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What does Spark do with my data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Storage Level:**\n",
    "- Does RDD use disk?\n",
    "- Does RDD use memory?\n",
    "- Does RDD use off-heap memory?\n",
    "- Should an RDD be serialized (while persisting)?\n",
    "- How many replicas (default: 1) to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "scala> textFile.getStorageLevel.useDisk\n",
    "scala> textFile.getStorageLevel.useMemory\n",
    "scala> textFile.getStorageLevel.useOffHeap\n",
    "scala> textFile.getStorageLevel.deserialized\n",
    "scala> textFile.getStorageLevel.replication\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set cache to Spark:\n",
    "\n",
    "```\n",
    "scala> textFile.cache\n",
    "scala> textFile.getStorageLevel\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By default, each transformed RDD may be recomputed each time you run an action on it.\n",
    "- It is also possible to *persist* RDD in memory using *persist()* or *cache()*\n",
    "    - *persist()* allows you to specify level of storage for RDD\n",
    "    - *cache()* only persists RDD in memory\n",
    "    - To retire RDD from memory, *unpersist()* is called"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. WordCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data operations in Spark are categorized into two groups, *transformation* and *action*. \n",
    "- A *transformation* creates new dataset from existing data. Examples of *transformation* include map, filter, reduceByKey, and sort. \n",
    "- An *action* returns a value to the driver program (aka memory space of this notebook) after running a computation on the data set. Examples of *action* include count, collect, reduce, and save. \n",
    "\n",
    "\"All transformations in Spark are lazy, in that they do not compute their results right away. Instead, they just remember the transformations applied to some base dataset (e.g. a file). The transformations are only computed when an action requires a result to be returned to the driver program.\" -- Spark Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RDD Operations in Spark\n",
    "\n",
    "**Transformations: **\n",
    "\n",
    "- *map*(f: T -> U) : RDD[T] -> RDD[U]\n",
    "- *filter*(f: T -> Bool) : RDD[T] -> RDD[T]\n",
    "- *flatMap*(f: T -> Seq[U]) : RDD[T] -> RDD[U]\n",
    "- *sample*(*fraction*: Float) : RDD[T] -> RDD[T] (deterministic sampling)\n",
    "- *groupByKey*() : RDD[(K,V)] -> RDD[(K, Seq[V])]\n",
    "- *reduceByKey*(f: (V,V) -> V) : RDD[(K,V)] -> RDD[(K,V)]\n",
    "- *union*() : (RDD[T], RDD[T]) -> RDD[T]\n",
    "- *join*() : (RDD[(K,V)], RDD[(K,W)]) -> RDD[(K,(V,W))]\n",
    "- *cogroup*() : (RDD[(K,V)], RDD[(K,W)] -> RDD[(K, (Seq[V],Seq[W]))]\n",
    "- *crossProduct*() : (RDD[T], RDD[U]) -> RDD[(T,U)]\n",
    "- *mapValues*(f: V -> W) : RDD[(K,V)] -> RDD[(K,W)] (preserves partitioning)\n",
    "- *sort*(c: Comparator[K]) :  RDD[(K,V)] -> RDD[(K,V)]\n",
    "- *partitionBy*(p: Partitioner[K]) : RDD[(K,V)] -> RDD[(K,V)]\n",
    "\n",
    "**Actions:**\n",
    "\n",
    "- *count*() : RDD[T] -> Long\n",
    "- *collect*() : RDD[T] -> Seq[T]\n",
    "- *reduce*(f: (T,T) -> T) : RDD[T] -> T\n",
    "- *lookup*(k : K) : RDD[(K,V)] -> Seq[V] (on hash/range partitionied RDDs)\n",
    "- *save*(path: String) : Outputs RDD to a storage system "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cache versus Cached\n",
    "\n",
    "Count how many lines there are in the file\n",
    "\n",
    "```\n",
    "scala> spark.time(textFile.count)\n",
    "```\n",
    "\n",
    "Recount\n",
    "\n",
    "```\n",
    "scala> spark.time(textFile.count)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "How to run wordcount\n",
    "\n",
    "```\n",
    "scala> val wordcount = textFile.flatMap(line => line.split(\" \")).map(word => (word, 1)).reduceByKey{case (x, y) => x + y}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[9] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/11/01 12:44:02 INFO fs.TrashPolicyDefault: Moved: 'hdfs://dsci/user/lngo/intro-to-spark' to trash at: hdfs://dsci/user/lngo/.Trash/Current/user/lngo/intro-to-spark\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r intro-to-spark\n",
    "!hdfs dfs -mkdir intro-to-spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordcount.saveAsTextFile(\"intro-to-spark/output-wordcount-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', 516839)\r\n",
      "('Quince', 1)\r\n",
      "('LIBRARY,', 218)\r\n",
      "('Just', 10)\r\n",
      "('enrooted', 1)\r\n",
      "('divers', 20)\r\n",
      "('Doubtless', 2)\r\n",
      "('undistinguishable,', 1)\r\n",
      "('Rheims,', 1)\r\n",
      "('Freedom!', 1)\r\n",
      "('incorporate.', 1)\r\n",
      "('bawd!', 3)\r\n",
      "('Sir-I', 1)\r\n",
      "('withering', 2)\r\n",
      "('Mopsa,', 1)\r\n",
      "('[BEROWNE', 3)\r\n",
      "('forgetfulness?', 1)\r\n",
      "('Tranio?', 1)\r\n",
      "('Wound', 3)\r\n",
      "('twice,', 2)\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat intro-to-spark/output-wordcount-01/part-00000 \\\n",
    "    2>/dev/null | head -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step-by-step actions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1609\r\n",
      "\r\n",
      "THE SONNETS\r\n",
      "\r\n",
      "by William Shakespeare\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "                     1\r\n",
      "  From fairest creatures we desire increase,\r\n",
      "  That thereby beauty's rose might never die,\r\n",
      "  But as the riper should by time decease,\r\n",
      "  His tender heir might bear his memory:\r\n",
      "  But thou contracted to thine own bright eyes,\r\n",
      "  Feed'st thy light's flame with self-substantial fuel,\r\n",
      "  Making a famine where abundance lies,\r\n",
      "  Thy self thy foe, to thy sweet self too cruel:\r\n",
      "  Thou that art now the world's fresh ornament,\r\n",
      "  And only herald to the gaudy spring,\r\n",
      "  Within thine own bud buriest thy content,\r\n",
      "  And tender churl mak'st waste in niggarding:\r\n",
      "    Pity the world, or else this glutton be,\r\n",
      "    To eat the world's due, by the grave and thee.\r\n",
      "\r\n",
      "\r\n",
      "                     2\r\n",
      "  When forty winters shall besiege thy brow,\r\n",
      "  And dig deep trenches in thy beauty's field,\r\n",
      "  Thy youth's proud livery so gazed on now,\r\n",
      "  Will be a tattered weed of small worth held:  \r\n",
      "  Then being asked, where all thy beauty lies,\r\n",
      "  Where all the treasure of thy lusty days;\r\n",
      "  To say within thine own deep sunken eyes,\r\n",
      "  Were an all-eating shame, and thriftless praise.\r\n",
      "  How much more praise deserved thy beauty's use,\r\n",
      "  If thou couldst answer 'This fair child of mine\r\n",
      "  Shall sum my count, and make my old excuse'\r\n",
      "  Proving his beauty by succession thine.\r\n",
      "    This were to be new made when thou art old,\r\n",
      "    And see thy blood warm when thou feel'st it cold.\r\n",
      "\r\n",
      "\r\n",
      "                     3\r\n",
      "  Look in thy glass and tell the face thou viewest,\r\n",
      "  Now is the time that face should form another,\r\n",
      "  Whose fresh repair if now thou not renewest,\r\n",
      "  Thou dost beguile the world, unbless some mother.\r\n",
      "  For where is she so fair whose uneared womb\r\n",
      "  Disdains the tillage of thy husbandry?\r\n",
      "  Or who is he so fond will be the tomb,\r\n",
      "  Of his self-love to stop posterity?  \r\n",
      "  Thou art thy mother's glass and she in thee\r\n",
      "  Calls back the lovely April of her prime,\r\n",
      "  So thou through windows of thine age shalt see,\r\n",
      "  Despite of wrinkles this thy golden time.\r\n",
      "    But if thou live remembered not to be,\r\n",
      "    Die single and thine image dies with thee.\r\n",
      "\r\n",
      "\r\n",
      "                     4\r\n",
      "  Unthrifty loveliness why dost thou spend,\r\n",
      "  Upon thy self thy beauty's legacy?\r\n",
      "  Nature's bequest gives nothing but doth lend,\r\n",
      "  And being frank she lends to those are free:\r\n",
      "  Then beauteous niggard why dost thou abuse,\r\n",
      "  The bounteous largess given thee to give?\r\n",
      "  Profitless usurer why dost thou use\r\n",
      "  So great a sum of sums yet canst not live?\r\n",
      "  For having traffic with thy self alone,\r\n",
      "  Thou of thy self thy sweet self dost deceive,\r\n",
      "  Then how when nature calls thee to be gone,\r\n",
      "  What acceptable audit canst thou leave?  \r\n",
      "    Thy unused beauty must be tombed with thee,\r\n",
      "    Which used lives th' executor to be.\r\n",
      "\r\n",
      "\r\n",
      "                     5\r\n",
      "  Those hours that with gentle work did frame\r\n",
      "  The lovely gaze where every eye doth dwell\r\n",
      "  Will play the tyrants to the very same,\r\n",
      "  And that unfair which fairly doth excel:\r\n",
      "  For never-resting time leads summer on\r\n",
      "  To hideous winter and confounds him there,\r\n",
      "  Sap checked with frost and lusty leaves quite gone,\r\n",
      "  Beauty o'er-snowed and bareness every where:\r\n",
      "  Then were not summer's distillation left\r\n",
      "  A liquid prisoner pent in walls of glass,\r\n",
      "  Beauty's effect with beauty were bereft,\r\n",
      "  Nor it nor no remembrance what it was.\r\n",
      "    But flowers distilled though they with winter meet,\r\n",
      "    Leese but their show, their substance still lives sweet.\r\n",
      "\r\n",
      "\r\n",
      "                     6  \r\n",
      "  Then let not winter's ragged hand deface,\r\n",
      "  In thee thy summer ere thou be distilled:\r\n",
      "  Make sweet some vial; treasure thou some place,\r\n",
      "  With beauty's treasure ere it be self-killed:\r\n",
      "  That use is not forbidden usury,\r\n",
      "  Which happies those that pay the willing loan;\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /repository/gutenberg-shakespeare.txt \\\n",
    "    2>/dev/null | head -n 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordcount_step_01 = textFile.flatMap(lambda line: line.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[13] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcount_step_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1609',\n",
       " '',\n",
       " 'THE',\n",
       " 'SONNETS',\n",
       " '',\n",
       " 'by',\n",
       " 'William',\n",
       " 'Shakespeare',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcount_step_01.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordcount_step_02 = wordcount_step_01.map(lambda word: (word, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1609', 1),\n",
       " ('', 1),\n",
       " ('THE', 1),\n",
       " ('SONNETS', 1),\n",
       " ('', 1),\n",
       " ('by', 1),\n",
       " ('William', 1),\n",
       " ('Shakespeare', 1),\n",
       " ('', 1),\n",
       " ('', 1),\n",
       " ('', 1),\n",
       " ('', 1),\n",
       " ('', 1),\n",
       " ('', 1),\n",
       " ('', 1),\n",
       " ('', 1),\n",
       " ('', 1),\n",
       " ('', 1),\n",
       " ('', 1),\n",
       " ('', 1)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcount_step_02.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordcount_step_03 = wordcount_step_02.reduceByKey(lambda a, b: a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 516839),\n",
       " ('Quince', 1),\n",
       " ('LIBRARY,', 218),\n",
       " ('Just', 10),\n",
       " ('enrooted', 1),\n",
       " ('divers', 20),\n",
       " ('Doubtless', 2),\n",
       " ('undistinguishable,', 1),\n",
       " ('Rheims,', 1),\n",
       " ('Freedom!', 1),\n",
       " ('incorporate.', 1),\n",
       " ('bawd!', 3),\n",
       " ('Sir-I', 1),\n",
       " ('withering', 2),\n",
       " ('Mopsa,', 1),\n",
       " ('[BEROWNE', 3),\n",
       " ('forgetfulness?', 1),\n",
       " ('Tranio?', 1),\n",
       " ('Wound', 3),\n",
       " ('twice,', 2)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcount_step_03.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "- Augment the mapping process of WordCount with a function to filter out punctuations and capitalization from the unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To stop the Spark job, call `sc.stop()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
