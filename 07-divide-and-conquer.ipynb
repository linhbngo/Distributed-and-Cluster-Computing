{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>Partitioning: Divide and Conquer</center>\n",
    "### <center> Linh B. Ngo </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Partitioning </center>\n",
    "\n",
    "Partitioning simply divides the problem into parts and then compute the parts and combine results\n",
    "\n",
    "- The basis of all parallel programming, in one form or another. \n",
    "\n",
    "- Pleasantly parallel used partitioning without any interaction between the parts.\n",
    "\n",
    "- Most partitioning  formulation require the results of the parts to be combined to obtain the desired results. \n",
    "\n",
    "- Partitioning can be applied to the program data. This is call data partitioning or domain decomposition.\n",
    "\n",
    "- Partitioning can also be applied to the functions of a program. This is called functional decomposition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Divide and Conquer </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Characterized by dividing problem into sub-problems of same form as larger problem. Further divisions into still smaller sub-problems, usually done by recursion.\n",
    "\n",
    "- Recursive divide and conquer amenable to parallelization because separate processes can be used for divided pairs. Also usually data is naturally localized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/07/dc01.png\" width=\"700\"/> \n",
    "<sub>Wilkinson, Barry, and Michael Allen. Parallel programming. 2nd Ed. 2003. </sub>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/07/divide.png\" width=\"700\"/> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/divide.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/divide.c\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include \"mpi.h\"\n",
    "\n",
    "int main(int argc, char * argv[] ) {\n",
    "  int rank;     /* rank of each MPI process */\n",
    "  int size;     /* total number of MPI processes */\n",
    "  int i;        /* counter */\n",
    "  int distance; /* distance between sender and receiver */\n",
    "    \n",
    "  MPI_Init(&argc,&argv);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD,&rank);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD,&size);\n",
    "    \n",
    "  /* Am I sender or receiver? */\n",
    "  /* Who am I sending/receiving to/from */\n",
    "  distance = 1;\n",
    "  i = 1;\n",
    "  while (distance <= size / 2){      \n",
    "    if (rank < distance) {\n",
    "      printf (\"At time step %d, sender %d sends to %d\\n\", i, rank, rank + distance);\n",
    "    }\n",
    "    if ((rank >= distance) && (rank < distance * 2)){\n",
    "      printf (\"At time step %d, receiver %d receives from %d\\n\", i, rank, rank - distance);\n",
    "    }\n",
    "    printf (\"Process %d has distance value %d and time step %d\\n\", rank, distance, i);\n",
    "    distance = distance * 2;\n",
    "    i += 1;\n",
    "  }\n",
    "    \n",
    "  MPI_Finalize();\n",
    "  return 0;  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At time step 1, sender 0 sends to 1\r\n",
      "Process 0 has distance value 1 and time step 1\r\n",
      "At time step 2, sender 0 sends to 2\r\n",
      "Process 0 has distance value 2 and time step 2\r\n",
      "At time step 3, sender 0 sends to 4\r\n",
      "Process 0 has distance value 4 and time step 3\r\n",
      "At time step 1, receiver 1 receives from 0\r\n",
      "Process 1 has distance value 1 and time step 1\r\n",
      "At time step 2, sender 1 sends to 3\r\n",
      "Process 1 has distance value 2 and time step 2\r\n",
      "At time step 3, sender 1 sends to 5\r\n",
      "Process 1 has distance value 4 and time step 3\r\n",
      "Process 3 has distance value 1 and time step 1\r\n",
      "At time step 2, receiver 3 receives from 1\r\n",
      "Process 3 has distance value 2 and time step 2\r\n",
      "At time step 3, sender 3 sends to 7\r\n",
      "Process 3 has distance value 4 and time step 3\r\n",
      "Process 4 has distance value 1 and time step 1\r\n",
      "Process 4 has distance value 2 and time step 2\r\n",
      "At time step 3, receiver 4 receives from 0\r\n",
      "Process 4 has distance value 4 and time step 3\r\n",
      "Process 5 has distance value 1 and time step 1\r\n",
      "Process 5 has distance value 2 and time step 2\r\n",
      "At time step 3, receiver 5 receives from 1\r\n",
      "Process 5 has distance value 4 and time step 3\r\n",
      "Process 2 has distance value 1 and time step 1\r\n",
      "At time step 2, receiver 2 receives from 0\r\n",
      "Process 2 has distance value 2 and time step 2\r\n",
      "At time step 3, sender 2 sends to 6\r\n",
      "Process 2 has distance value 4 and time step 3\r\n",
      "Process 6 has distance value 1 and time step 1\r\n",
      "Process 6 has distance value 2 and time step 2\r\n",
      "At time step 3, receiver 6 receives from 2\r\n",
      "Process 6 has distance value 4 and time step 3\r\n",
      "Process 7 has distance value 1 and time step 1\r\n",
      "Process 7 has distance value 2 and time step 2\r\n",
      "At time step 3, receiver 7 receives from 3\r\n",
      "Process 7 has distance value 4 and time step 3\r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/divide.c -lm -o ~/divide\n",
    "!mpirun -np 8 --map-by core:OVERSUBSCRIBE ~/divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/conquer.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/conquer.c\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include \"mpi.h\"\n",
    "\n",
    "int main(int argc, char * argv[] ) {\n",
    "  int rank;     /* rank of each MPI process */\n",
    "  int size;     /* total number of MPI processes */\n",
    "  int i;        /* counter */\n",
    "  int distance; /* distance between sender and receiver */\n",
    "    \n",
    "  MPI_Init(&argc,&argv);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD,&rank);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD,&size);\n",
    "    \n",
    "  /* Am I sender or receiver? */\n",
    "  /* Who am I sending/receiving to/from */\n",
    "  distance = (int)(size / 2);\n",
    "    \n",
    "  i = 1;\n",
    "  while (distance >= 1){      \n",
    "    if ((rank >= distance) && (rank < distance * 2)){\n",
    "      printf (\"At time step %d, sender %d sends to %d\\n\", i, rank, rank - distance);\n",
    "    }\n",
    "    if (rank < distance) {\n",
    "      printf (\"At time step %d, receiver %d receives from %d\\n\", i, rank, rank + distance);\n",
    "    }\n",
    "    distance = distance / 2;\n",
    "    i += 1;\n",
    "  }\n",
    "    \n",
    "  MPI_Finalize();\n",
    "  return 0;  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At time step 1, receiver 0 receives from 4\r\n",
      "At time step 2, receiver 0 receives from 2\r\n",
      "At time step 3, receiver 0 receives from 1\r\n",
      "At time step 1, sender 4 sends to 0\r\n",
      "At time step 1, sender 6 sends to 2\r\n",
      "At time step 1, receiver 3 receives from 7\r\n",
      "At time step 2, sender 3 sends to 1\r\n",
      "At time step 1, receiver 2 receives from 6\r\n",
      "At time step 2, sender 2 sends to 0\r\n",
      "At time step 1, receiver 1 receives from 5\r\n",
      "At time step 2, receiver 1 receives from 3\r\n",
      "At time step 3, sender 1 sends to 0\r\n",
      "At time step 1, sender 7 sends to 3\r\n",
      "At time step 1, sender 5 sends to 1\r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/conquer.c -lm -o ~/conquer\n",
    "!mpirun -np 8 --map-by core:OVERSUBSCRIBE ~/conquer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Many sorting algorithms can be parallelized by partitioning using\n",
    "divide and conquer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Bucket Sort </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/07/bucketsort1.png\" width=\"700\"/> \n",
    "<sub>Wilkinson, Barry, and Michael Allen. Parallel programming. 2nd Ed. 2003. </sub>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Simple approach to parallel bucket sort **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/07/bucketsort2.png\" width=\"700\"/> \n",
    "<sub>Wilkinson, Barry, and Michael Allen. Parallel programming. 2nd Ed. 2003. </sub>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Broadcast data\n",
    "- Sort only those elements that fit in local interval bucket (determined by rank)\n",
    "- Gather sorted bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "int MPI_Scatter(\n",
    "    void *sendbuf, \n",
    "    int sendcount, \n",
    "    MPI_Datatype sendtype, \n",
    "    void *recvbuf,\n",
    "    int recvcnt,\n",
    "    MPI_Datatype recvtype,\n",
    "    int root, \n",
    "    MPI_Comm comm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "int MPI_Scatterv(\n",
    "  void *sendbuf,\n",
    "  int *sendcnts,\n",
    "  int *displs,\n",
    "  MPI_Datatype sendtype,\n",
    "  void *recvbuf,\n",
    "  int recvcnt,\n",
    "  MPI_Datatype recvtype,\n",
    "  int root,\n",
    "  MPI_Comm comm\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- sendbuf: address of send buffer (choice, significant only at root)\n",
    "- sendcounts: integer array (of length group size) specifying the number of elements to send to each processor\n",
    "- displs: integer array (of length group size). Entry i specifies the displacement (relative to sendbuf from which to take the outgoing data to process i\n",
    "- sendtype: data type of send buffer elements\n",
    "- recvbuf: address of receive buffer (choice)\n",
    "- recvcount: number of elements in receive buffer (integer)\n",
    "- recvtype: data type of receive buffer elements \n",
    "- root: rank of sending process (integer)\n",
    "- comm: communicator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/scatterv.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/scatterv.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "int main(int argc, char *argv[])\n",
    "{\n",
    "    int rank, size;    \n",
    "    int i; \n",
    "    int sendcounts[4] = {1,2,3,4}; /* each process will receive its rank plus 1 numbers from the sendbuf array */\n",
    "    int displs[4] = {0,0,0,0}; /* array describing the displacements where each segment begins and is initialized to all 0s */\n",
    "    int sendbuf[10] = {2,13,4,3,5,1,0,12,10,8}; /* the buffer to be sent */\n",
    "    int *recvbuf; /* array at each process to receive data. To be initialized based on process rank */\n",
    "\n",
    "    MPI_Init(&argc, &argv);\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "    /* initializes recvbuf to contain exactly rank plus 1 numbers */\n",
    "    recvbuf = malloc(sizeof(int)* (rank + 1));\n",
    "    \n",
    "    // calculate displacements\n",
    "    for (i = 1; i < 4; i++) {\n",
    "        displs[i] = displs[i-1] + sendcounts[i-1];\n",
    "    }\n",
    "\n",
    "    // divide the data among processes as described by sendcounts and displs\n",
    "    MPI_Scatterv(sendbuf, sendcounts, displs, MPI_INT, recvbuf, (rank + 1), MPI_INT, 0, MPI_COMM_WORLD);\n",
    "\n",
    "    // print what each process received\n",
    "    printf(\"%d: \", rank);\n",
    "    for (i = 0; i < sendcounts[rank]; i++) {\n",
    "        printf(\"%d \", recvbuf[i]);\n",
    "    }\n",
    "    printf(\"\\n\");\n",
    "    \n",
    "    free(recvbuf);\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 2 \r\n",
      "1: 13 4 \r\n",
      "2: 3 5 1 \r\n",
      "3: 0 12 10 8 \r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/scatterv.c -o ~/scatterv\n",
    "!mpirun -np 4 --map-by core:OVERSUBSCRIBE ~/scatterv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "int MPI_Gather(\n",
    "    void *sendbuff, \n",
    "    int sendcount, \n",
    "    MPI_Datatype sendtype, \n",
    "    void *recvbuff,\n",
    "    int recvcnt,\n",
    "    MPI_Datatype recvtype,\n",
    "    int root, \n",
    "    MPI_Comm comm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "int MPI_Gatherv(\n",
    "  void *sendbuf,\n",
    "  int sendcnt,\n",
    "  MPI_Datatype sendtype,\n",
    "  void *recvbuf,\n",
    "  int *recvcnts,\n",
    "  int *displs,\n",
    "  MPI_Datatype recvtype,\n",
    "  int root,\n",
    "  MPI_Comm comm\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- sendbuf: starting address of send buffer (choice)\n",
    "- sendcount: number of elements in send buffer (integer)\n",
    "- sendtype: data type of send buffer elements \n",
    "- recvbuf: address of receive buffer (choice, significant only at root)\n",
    "- recvcounts: integer array (of length group size) containing the number of elements that are received from each process (significant only at root)\n",
    "- displs: integer array (of length group size). Entry i specifies the displacement relative to recvbuf at which to place the incoming data from process i (significant only at root)\n",
    "- recvtype: data type of recv buffer elements (significant only at root)\n",
    "- root: rank of receiving process (integer)\n",
    "- comm: communicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/gatherv.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/gatherv.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "int main(int argc, char *argv[])\n",
    "{\n",
    "    int rank, size;    \n",
    "    int i; \n",
    "    int recvcounts[4] = {1,2,3,4}; /* process 0 will receive from each process that process rank */\n",
    "                                   /* plus 1 numbers */\n",
    "    int displs[4] = {0,0,0,0}; /* array describing the displacements where each segment begins and is initialized to all 0s */\n",
    "    int *sendbuf; /* the buffer to be sent. will be initialized individually at each process */\n",
    "    int *recvbuf; /* arrayto receive data. will only be initialized at process 0*/\n",
    "\n",
    "    MPI_Init(&argc, &argv);\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "    /* initializes recvbuf to receive 10 numbers */\n",
    "    if (rank == 0){\n",
    "      recvbuf = malloc(sizeof(int) * (10));\n",
    "\n",
    "      for (i = 0; i < 10; i ++)\n",
    "        recvbuf[i] = -1;\n",
    "    }\n",
    "    \n",
    "    /* initializes sendbuf to receive 10 numbers */\n",
    "    sendbuf = malloc(sizeof(int) * (rank + 1));\n",
    "    for (i = 0; i < (rank + 1); i++){\n",
    "        sendbuf[i] = rank;\n",
    "    }\n",
    "    \n",
    "    // calculate displacements\n",
    "    for (i = 1; i < 4; i++) {\n",
    "        displs[i] = displs[i-1] + recvcounts[i-1] - 1;\n",
    "    }\n",
    "\n",
    "    // divide the data among processes as described by sendcounts and displs\n",
    "    MPI_Gatherv(sendbuf, rank + 1, MPI_INT, recvbuf, recvcounts, displs, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "\n",
    "    // print what process has at the end\n",
    "    if (rank == 0){\n",
    "      for (i = 0; i < 10; i++) {\n",
    "        printf(\"%d \", recvbuf[i]);\n",
    "      }\n",
    "      printf(\"\\n\");\n",
    "      free(recvbuf);\n",
    "    }\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 2 3 3 3 3 -1 -1 -1 \r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/gatherv.c -o ~/gatherv\n",
    "!mpirun -np 4 --map-by core:OVERSUBSCRIBE ~/gatherv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Parallel Bucket Sort version 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/bucket1.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/bucket1.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define N 64\n",
    "\n",
    "int main(int argc, char* argv[]){\n",
    "\n",
    "  int rawNum[N];\n",
    "  int sortNum[N];\n",
    "  int* local_bucket;\n",
    "  int rank,size;\n",
    "  int* proc_count;\n",
    "  int* disp;\n",
    "  MPI_Status status;\n",
    "  int i,j,counter;\n",
    "  int local_min,local_max;\n",
    "  int tmp;\n",
    "\n",
    "  MPI_Init(&argc,&argv);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD,&rank);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD,&size);\n",
    "    \n",
    "  if (rank == 0){\n",
    "    /* Initialize a random array with N integers whose values range between 0 and N */\n",
    "    for (i = 0; i < N; i++){\n",
    "      rawNum[i] = rand() % N;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  /* Broadcast contents of rawNum from 0 to all other processes */\n",
    "  MPI_Bcast(rawNum, N, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "\n",
    "  /* Each process only works with numbers within their assigned interval */\n",
    "  counter = 0;\n",
    "  local_min = rank * (N/size);\n",
    "  local_max = (rank + 1) * (N/size);  \n",
    "  for (i = 0; i < N; i++){\n",
    "    if ((rawNum[i] >= local_min) && (rawNum[i] < local_max)){\n",
    "      counter += 1;\n",
    "    }\n",
    "  }    \n",
    "    \n",
    "  printf(\"For rank %d, max is %d, min is %d, and there are %d elements in rawNum that falls within max and min \\n\",\n",
    "         rank,local_max,local_min,counter);\n",
    "\n",
    "\n",
    "  /* Each process creates its own bucket containing values that fall within its interval */  \n",
    "  local_bucket = malloc(counter * sizeof(int));\n",
    "  counter = 0;\n",
    "  for (i = 0; i < N; i++){\n",
    "    if ((rawNum[i] >= local_min) && (rawNum[i] < local_max)){\n",
    "      local_bucket[counter] = rawNum[i];\n",
    "      counter += 1;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  /* Insertion sort */\n",
    "  for (i = 0; i < counter; i++){\n",
    "    for (j = i+1; j < counter; j++){\n",
    "      if (local_bucket[i] > local_bucket[j]){\n",
    "        tmp = local_bucket[i];\n",
    "        local_bucket[i] = local_bucket[j];\n",
    "        local_bucket[j] = tmp;\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "\n",
    "  for (i = 0; i < counter; i++){\n",
    "    printf(\"%d %d \\n\",rank,local_bucket[i]);\n",
    "  }\n",
    "\n",
    "  /* set up root process */\n",
    "  if (rank == 0){\n",
    "    proc_count = malloc(size * sizeof(int));\n",
    "    disp = malloc(size * sizeof(int));\n",
    "  }\n",
    "\n",
    "  /* populate proc_count */\n",
    "  MPI_Gather(&counter,1,MPI_INT,proc_count,1,MPI_INT,0,MPI_COMM_WORLD);\n",
    "\n",
    "  if (rank == 0){\n",
    "    disp[0] = 0;\n",
    "    for (i = 0; i < size-1; i++){\n",
    "      disp[i+1] = disp[i] + proc_count[i];\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // receive final result\n",
    "  MPI_Gatherv(local_bucket,counter,MPI_INT,sortNum,proc_count,disp,MPI_INT,0,MPI_COMM_WORLD);\n",
    "\n",
    "  if (rank == 0){\n",
    "    printf(\"Before sort: \\n\");\n",
    "    for (i = 0; i < N; i++) printf(\"%d \",rawNum[i]);\n",
    "    printf(\"\\nAfter sort: \\n\");\n",
    "    for (i = 0; i < N; i++) printf(\"%d \",sortNum[i]);\n",
    "  }\n",
    "\n",
    "  MPI_Finalize();\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 0, max is 8, min is 0, and there are 8 elements in rawNum that falls within max and min \n",
      "0 1 \n",
      "0 2 \n",
      "0 2 \n",
      "0 5 \n",
      "0 6 \n",
      "0 6 \n",
      "0 6 \n",
      "0 7 \n",
      "For rank 2, max is 24, min is 16, and there are 6 elements in rawNum that falls within max and min \n",
      "2 17 \n",
      "2 17 \n",
      "2 20 \n",
      "2 20 \n",
      "2 20 \n",
      "2 23 \n",
      "For rank 4, max is 40, min is 32, and there are 8 elements in rawNum that falls within max and min \n",
      "4 33 \n",
      "4 35 \n",
      "4 35 \n",
      "4 35 \n",
      "4 37 \n",
      "4 38 \n",
      "4 39 \n",
      "4 39 \n",
      "For rank 1, max is 16, min is 8, and there are 7 elements in rawNum that falls within max and min \n",
      "1 9 \n",
      "1 10 \n",
      "1 13 \n",
      "1 13 \n",
      "1 13 \n",
      "1 13 \n",
      "1 14 \n",
      "For rank 5, max is 48, min is 40, and there are 8 elements in rawNum that falls within max and min \n",
      "5 40 \n",
      "5 41 \n",
      "5 41 \n",
      "5 41 \n",
      "5 43 \n",
      "5 43 \n",
      "5 44 \n",
      "5 46 \n",
      "For rank 3, max is 32, min is 24, and there are 11 elements in rawNum that falls within max and min \n",
      "3 24 \n",
      "3 24 \n",
      "3 26 \n",
      "3 26 \n",
      "3 26 \n",
      "3 27 \n",
      "3 27 \n",
      "3 28 \n",
      "3 29 \n",
      "3 30 \n",
      "3 31 \n",
      "For rank 6, max is 56, min is 48, and there are 10 elements in rawNum that falls within max and min \n",
      "6 49 \n",
      "6 50 \n",
      "6 50 \n",
      "6 50 \n",
      "6 51 \n",
      "6 51 \n",
      "6 52 \n",
      "6 52 \n",
      "6 54 \n",
      "6 55 \n",
      "For rank 7, max is 64, min is 56, and there are 6 elements in rawNum that falls within max and min \n",
      "7 56 \n",
      "7 58 \n",
      "7 59 \n",
      "7 60 \n",
      "7 61 \n",
      "7 63 \n",
      "Before sort: \n",
      "39 6 41 51 17 63 10 44 41 13 58 43 50 59 35 6 60 2 20 56 27 40 39 13 54 26 46 35 51 31 9 26 38 50 13 55 49 24 35 26 37 29 5 23 24 41 30 20 43 50 13 6 27 52 20 17 14 2 52 1 33 61 28 7 \n",
      "After sort: \n",
      "1 2 2 5 6 6 6 7 9 10 13 13 13 13 14 17 17 20 20 20 23 24 24 26 26 26 27 27 28 29 30 31 33 35 35 35 37 38 39 39 40 41 41 41 43 43 44 46 49 50 50 50 51 51 52 52 54 55 56 58 59 60 61 63 "
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/bucket1.c -o ~/bucket1\n",
    "!mpirun -np 8 --map-by core:OVERSUBSCRIBE ~/bucket1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The data might be too large to be distributed via MPI_Bcast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/07/bucketsort3.png\" width=\"700\"/> \n",
    "<sub>Wilkinson, Barry, and Michael Allen. Parallel programming. 2nd Ed. 2003. </sub>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/07/all2all.png\" width=\"700\"/> \n",
    "<sub>Wilkinson, Barry, and Michael Allen. Parallel programming. 2nd Ed. 2003. </sub>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/07/all2all_2.png\" width=\"700\"/> \n",
    "<sub>Wilkinson, Barry, and Michael Allen. Parallel programming. 2nd Ed. 2003. </sub>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "int MPI_Alltoall(\n",
    "  void *sendbuf,\n",
    "  int sendcount,\n",
    "  MPI_Datatype sendtype,\n",
    "  void *recvbuf,\n",
    "  int recvcount,\n",
    "  MPI_Datatype recvtype,\n",
    "  MPI_Comm comm\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- sendbuf: starting address of send buffer (choice)\n",
    "- sendcount: number of elements to send to each process (integer)\n",
    "- sendtype: data type of send buffer elements\n",
    "- recvbuf: address of receive buffer (choice)\n",
    "- recvcount: number of elements received from any process (integer)\n",
    "- recvtype: data type of receive buffer elements\n",
    "- comm: communicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/alltoall.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/alltoall.c\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <mpi.h>\n",
    "\n",
    "int main(int argc,char *argv[]){\n",
    "  int rank, size;\n",
    "  int *sray,*rray;\n",
    "  int *sdisp,*scounts,*rdisp,*rcounts;\n",
    "  int ssize,rsize,i,k,j;\n",
    "  float z;\n",
    "\n",
    "  MPI_Init(&argc,&argv);\n",
    "  MPI_Comm_size( MPI_COMM_WORLD, &size);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    \n",
    "  scounts=(int*)malloc(sizeof(int)*size);\n",
    "  rcounts=(int*)malloc(sizeof(int)*size);\n",
    "  sdisp=(int*)malloc(sizeof(int)*size);\n",
    "  rdisp=(int*)malloc(sizeof(int)*size);\n",
    "\n",
    "  z = (float) rand() / RAND_MAX;\n",
    "    \n",
    "  for(i=0; i < size; i++){\n",
    "    scounts[i]= rank * i + i;\n",
    "  }\n",
    "  \n",
    "  printf(\"myid = %d scounts = \",rank);\n",
    "  for(i=0;i<size;i++)\n",
    "    printf(\"%d \",scounts[i]);\n",
    "  printf(\"\\n\");\n",
    "\n",
    "  /* send the data */\n",
    "  MPI_Alltoall(scounts,1,MPI_INT,rcounts,1,MPI_INT,MPI_COMM_WORLD);\n",
    "  printf(\"myid = %d rcounts = \",rank);\n",
    "  for(i=0;i<size;i++)\n",
    "    printf(\"%d \",rcounts[i]);\n",
    "  printf(\"\\n\");\n",
    "  MPI_Finalize();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myid = 3 scounts = 0 4 8 12 \r\n",
      "myid = 2 scounts = 0 3 6 9 \r\n",
      "myid = 1 scounts = 0 2 4 6 \r\n",
      "myid = 0 scounts = 0 1 2 3 \r\n",
      "myid = 3 rcounts = 3 6 9 12 \r\n",
      "myid = 1 rcounts = 1 2 3 4 \r\n",
      "myid = 2 rcounts = 2 4 6 8 \r\n",
      "myid = 0 rcounts = 0 0 0 0 \r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/alltoall.c -o ~/alltoall\n",
    "!mpirun -np 4 --map-by core:OVERSUBSCRIBE ~/alltoall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "int MPI_Alltoallv(\n",
    "  void *sendbuf,\n",
    "  int *sendcnts,\n",
    "  int *sdispls,\n",
    "  MPI_Datatype sendtype,\n",
    "  void *recvbuf,\n",
    "  int *recvcnts,\n",
    "  int *rdispls,\n",
    "  MPI_Datatype recvtype,\n",
    "  MPI_Comm comm\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- sendbuf: starting address of send buffer (choice)\n",
    "- sendcounts: integer array equal to the group size specifying the number of elements to send to each processor\n",
    "- sdispls: integer array (of length group size). Entry j specifies the displacement (relative to sendbuf from which to take the outgoing data destined for process j\n",
    "- sendtype: data type of send buffer elements\n",
    "- recvbuf: address of receive buffer (choice)\n",
    "- recvcounts: integer array equal to the group size specifying the maximum number of elements that can be received from each processor\n",
    "- rdispls: integer array (of length group size). Entry i specifies the displacement (relative to recvbuf at which to place the incoming data from process i\n",
    "- recvtype: data type of receive buffer elements\n",
    "- comm: communicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/alltoallv.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/alltoallv.c\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <mpi.h>\n",
    "\n",
    "int main(int argc,char *argv[]){\n",
    "  int size, rank; \n",
    "  int *sray,*rray;\n",
    "  int *sdisp,*scounts,*rdisp,*rcounts;\n",
    "  int ssize,rsize,i,k,j;\n",
    "  float z;\n",
    "\n",
    "  MPI_Init(&argc,&argv);\n",
    "  MPI_Comm_size( MPI_COMM_WORLD, &size);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    \n",
    "  scounts=(int*)malloc(sizeof(int)*size);\n",
    "  rcounts=(int*)malloc(sizeof(int)*size);\n",
    "  sdisp=(int*)malloc(sizeof(int)*size);\n",
    "  rdisp=(int*)malloc(sizeof(int)*size);\n",
    "\n",
    "  \n",
    "  /* find out how much data to send */\n",
    "  srand((unsigned int) rank);    \n",
    "  for(i=0;i<size;i++){\n",
    "    z = (float) rand()/RAND_MAX;\n",
    "    scounts[i]=(int)(5.0 * z) + 1;\n",
    "  }\n",
    "    \n",
    "  printf(\"rank= %d scounts= %d %d %d %d\\n\",rank,scounts[0],scounts[1],scounts[2],scounts[3]);\n",
    "\n",
    "  for(i=0;i<size;i++)\n",
    "    printf(\"%d \",scounts[i]);\n",
    "  printf(\"\\n\");\n",
    "    \n",
    "  /* tell the other processors how much data is coming */\n",
    "  MPI_Alltoall(scounts,1,MPI_INT,rcounts,1,MPI_INT,MPI_COMM_WORLD);\n",
    "\n",
    "  /* calculate displacements and the size of the arrays */\n",
    "  sdisp[0]=0;\n",
    "  for(i=1;i<size;i++){\n",
    "    sdisp[i]=scounts[i-1]+sdisp[i-1];\n",
    "  }\n",
    "  rdisp[0]=0;\n",
    "  for(i=1;i<size;i++){\n",
    "    rdisp[i]=rcounts[i-1]+rdisp[i-1];\n",
    "  }\n",
    "  ssize=0;\n",
    "  rsize=0;\n",
    "  for(i=0;i<size;i++){\n",
    "    ssize=ssize+scounts[i];\n",
    "    rsize=rsize+rcounts[i];\n",
    "  }\n",
    "  \n",
    "  /* allocate send and rec arrays */\n",
    "  sray=(int*)malloc(sizeof(int)*ssize);\n",
    "  rray=(int*)malloc(sizeof(int)*rsize);\n",
    "  for(i=0;i<ssize;i++)\n",
    "    sray[i]=rank;\n",
    "\n",
    "  /* send/rec different amounts of data to/from each processor */\n",
    "  MPI_Alltoallv( sray,scounts,sdisp,MPI_INT,rray,rcounts,rdisp,MPI_INT,MPI_COMM_WORLD);\n",
    "                  \n",
    "  printf(\"rank= %d rray=\",rank);\n",
    "  for(i=0;i<rsize;i++)\n",
    "    printf(\"%d \",rray[i]);\n",
    "  printf(\"\\n\");\n",
    "  MPI_Finalize();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank= 1 scounts= 5 2 4 4\r\n",
      "5 2 4 4 \r\n",
      "rank= 2 scounts= 4 5 1 1\r\n",
      "4 5 1 1 \r\n",
      "rank= 0 scounts= 5 2 4 4\r\n",
      "5 2 4 4 \r\n",
      "rank= 3 scounts= 3 2 2 3\r\n",
      "3 2 2 3 \r\n",
      "rank= 1 rray=0 0 1 1 2 2 2 2 2 3 3 \r\n",
      "rank= 0 rray=0 0 0 0 0 1 1 1 1 1 2 2 2 2 3 3 3 \r\n",
      "rank= 2 rray=0 0 0 0 1 1 1 1 2 3 3 \r\n",
      "rank= 3 rray=0 0 0 0 1 1 1 1 2 3 3 3 \r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/alltoallv.c -o ~/alltoallv\n",
    "!mpirun -np 4 --map-by core:OVERSUBSCRIBE ~/alltoallv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/bucket2.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/bucket2.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define N 32\n",
    "\n",
    "int main(int argc, char* argv[]){\n",
    "\n",
    "  int rank,size;\n",
    "  MPI_Status status;\n",
    "\n",
    "  int rawNum[N];\n",
    "  int sortNum[N];\n",
    "  int* local_array;\n",
    "\n",
    "  int i,j;\n",
    "\n",
    "  MPI_Init(&argc,&argv);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD,&rank);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD,&size);\n",
    "\n",
    "  // initialize the unsorted array at process 0\n",
    "  if (rank == 0){\n",
    "    for (i = 0; i < N; i++){\n",
    "      rawNum[i] = rand() % N;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // prepare the local container, then distribution equal portions of the\n",
    "  // unsorted array to all the processes from process 0\n",
    "  local_array = malloc((N/size) * sizeof(int));\n",
    "  MPI_Scatter(rawNum,(N/size),MPI_INT,local_array,(N/size),MPI_INT,0,MPI_COMM_WORLD);\n",
    "\n",
    "  // initialize the local bucket matrix\n",
    "  int local_bucket[size][N/size];\n",
    "  for (i = 0; i < size; i++){\n",
    "    for (j = 0; j < N/size; j++){\n",
    "      local_bucket[i][j] = RAND_MAX;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  int counter = 0;\n",
    "  int local_min,local_max;\n",
    " // populate the bucket matrix\n",
    "  for (i = 0; i < size; i++){\n",
    "    counter = 0;\n",
    "    for (j = 0; j < N/size; j++){\n",
    "      local_min = i * N/size;\n",
    "      local_max = (i + 1) * N / size;\n",
    "      if ((local_array[j] >= local_min)&&(local_array[j] < local_max)){\n",
    "        local_bucket[i][counter] = local_array[j];\n",
    "        counter += 1;\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // sort the bucket matrix. \n",
    "  int tmp = 0;\n",
    "  for (i = 0; i < size; i++){\n",
    "    for (j = 0; j < N/size; j++){\n",
    "      for (counter = j; counter < N/size; counter++){\n",
    "        if (local_bucket[i][j] > local_bucket[i][counter]){\n",
    "          tmp = local_bucket[i][j];\n",
    "          local_bucket[i][j] = local_bucket[i][counter];\n",
    "          local_bucket[i][counter] = tmp;\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // placing the number from the buckets back into the main array\n",
    "  counter = 0;\n",
    "  int array_counter[size];\n",
    "  for (i = 0; i < size; i++){\n",
    "    for (j = 0; j < N/size; j++){\n",
    "      if (local_bucket[i][j] != RAND_MAX){\n",
    "        local_array[counter] = local_bucket[i][j];\n",
    "        counter += 1;\n",
    "      }\n",
    "      else {\n",
    "        array_counter[i] = j;\n",
    "        printf(\"Rank %d counter %d \\n\",rank,array_counter[i]);\n",
    "        break;\n",
    "      }\n",
    "    }\n",
    "  }\n",
    " /*\n",
    "  for (i = 0; i < N/size; i++){\n",
    "    printf(\"rank %d sorted num %d \\n\",rank,local_array[i]);\n",
    "  }\n",
    "  */\n",
    "\n",
    "  if (rank == 0)  printf(\"-----------------\\n\");\n",
    "  MPI_Barrier(MPI_COMM_WORLD);\n",
    "\n",
    "  // preparation for bucket gathering\n",
    "  int recvbuf[size];\n",
    "  int rdisp[size];\n",
    "  int sdisp[size];\n",
    "\n",
    "  sdisp[0] = 0;\n",
    "  for (i = 0; i < size - 1; i++){\n",
    "    sdisp[i+1] = sdisp[i] + array_counter[i];\n",
    "    printf(\"%d send displace %d \\n\",rank,sdisp[i+1]);\n",
    "  }\n",
    "\n",
    "  MPI_Alltoall(array_counter,1,MPI_INT,recvbuf,1,MPI_INT,MPI_COMM_WORLD);\n",
    "\n",
    "  MPI_Barrier(MPI_COMM_WORLD);\n",
    "\n",
    "  int sum = 0;\n",
    "  for (i = 0; i < size; i++){\n",
    "    sum += recvbuf[i];\n",
    "    printf(\"rank %d recvbuf %d \\n\",rank,recvbuf[i]);\n",
    "  }\n",
    "\n",
    "  printf(\"rank %d total recv buf %d \\n\", rank,sum);\n",
    "\n",
    "  MPI_Barrier(MPI_COMM_WORLD);\n",
    "\n",
    "  rdisp[0] = 0;\n",
    "  for (i = 0; i < size - 1; i++){\n",
    "    rdisp[i+1] = rdisp[i] + recvbuf[i];\n",
    "    printf(\"%d recv displace %d \\n\",rank,rdisp[i+1]);\n",
    "  }\n",
    "\n",
    "  int local_array_alltoall[sum];\n",
    "  // initialize local_array_alltoall for testing purpose\n",
    "  for (i = 0; i < sum; i++) local_array_alltoall[i] = -1;\n",
    "  MPI_Alltoallv(local_array,array_counter,sdisp,MPI_INT,local_array_alltoall,recvbuf,rdisp,MPI_INT,MPI_COMM_WORLD);\n",
    "\n",
    "  for (i = 0; i < sum; i++){\n",
    "    printf(\"rank %d semi-sorted num %d \\n\",rank,local_array_alltoall[i]);\n",
    "  }\n",
    "\n",
    "\n",
    "  // local sort on big bucket one more time\n",
    "  for (i = 0; i < sum; i++){\n",
    "    for (j = i; j < sum; j++){\n",
    "      if (local_array_alltoall[i] > local_array_alltoall[j]){\n",
    "        tmp = local_array_alltoall[i];\n",
    "        local_array_alltoall[i] = local_array_alltoall[j];\n",
    "        local_array_alltoall[j] = tmp;\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // preparation for the final gathering\n",
    "  int proc_count[size];\n",
    "  int disp[size];\n",
    "\n",
    "\n",
    "  MPI_Gather(&sum,1,MPI_INT,proc_count,1,MPI_INT,0,MPI_COMM_WORLD);\n",
    "\n",
    "  if (rank == 0){\n",
    "    disp[0] = 0;\n",
    "    for (i = 0; i < size-1; i++){\n",
    "      disp[i+1] = disp[i] + proc_count[i];\n",
    "    }\n",
    "  }\n",
    "\n",
    "  MPI_Gatherv(local_array_alltoall,sum,MPI_INT,sortNum,proc_count,disp,MPI_INT,0,MPI_COMM_WORLD);\n",
    "\n",
    "  if (rank == 0){\n",
    "    printf(\"Before sort: \\n\");\n",
    "    for (i = 0; i < N; i++) printf(\"%d \",rawNum[i]);\n",
    "    printf(\"\\nAfter sort: \\n\");\n",
    "    for (i = 0; i < N; i++) printf(\"%d \",sortNum[i]);\n",
    "  }\n",
    "MPI_Finalize();\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 counter 0 \n",
      "Rank 0 counter 2 \n",
      "Rank 0 counter 1 \n",
      "Rank 0 counter 0 \n",
      "Rank 0 counter 1 \n",
      "Rank 0 counter 0 \n",
      "Rank 0 counter 0 \n",
      "Rank 0 counter 0 \n",
      "-----------------\n",
      "Rank 1 counter 0 \n",
      "Rank 1 counter 0 \n",
      "Rank 1 counter 1 \n",
      "Rank 1 counter 1 \n",
      "Rank 1 counter 1 \n",
      "Rank 1 counter 0 \n",
      "Rank 1 counter 0 \n",
      "Rank 1 counter 1 \n",
      "Rank 6 counter 1 \n",
      "Rank 6 counter 0 \n",
      "Rank 6 counter 0 \n",
      "Rank 6 counter 1 \n",
      "Rank 6 counter 0 \n",
      "Rank 6 counter 1 \n",
      "Rank 6 counter 1 \n",
      "Rank 6 counter 0 \n",
      "Rank 4 counter 1 \n",
      "Rank 4 counter 0 \n",
      "Rank 4 counter 0 \n",
      "Rank 4 counter 0 \n",
      "Rank 4 counter 0 \n",
      "Rank 4 counter 1 \n",
      "Rank 4 counter 1 \n",
      "Rank 4 counter 1 \n",
      "Rank 3 counter 1 \n",
      "Rank 3 counter 1 \n",
      "Rank 3 counter 0 \n",
      "Rank 3 counter 0 \n",
      "Rank 3 counter 1 \n",
      "Rank 3 counter 0 \n",
      "Rank 3 counter 1 \n",
      "Rank 3 counter 0 \n",
      "Rank 2 counter 0 \n",
      "Rank 2 counter 0 \n",
      "Rank 2 counter 2 \n",
      "Rank 2 counter 1 \n",
      "Rank 2 counter 0 \n",
      "Rank 2 counter 0 \n",
      "Rank 2 counter 1 \n",
      "Rank 2 counter 0 \n",
      "Rank 7 counter 0 \n",
      "Rank 7 counter 0 \n",
      "Rank 7 counter 1 \n",
      "Rank 7 counter 0 \n",
      "Rank 7 counter 1 \n",
      "Rank 7 counter 0 \n",
      "Rank 7 counter 1 \n",
      "Rank 7 counter 1 \n",
      "4 send displace 1 \n",
      "4 send displace 1 \n",
      "4 send displace 1 \n",
      "4 send displace 1 \n",
      "4 send displace 1 \n",
      "4 send displace 2 \n",
      "4 send displace 3 \n",
      "6 send displace 1 \n",
      "6 send displace 1 \n",
      "6 send displace 1 \n",
      "6 send displace 2 \n",
      "6 send displace 2 \n",
      "6 send displace 3 \n",
      "6 send displace 4 \n",
      "Rank 5 counter 0 \n",
      "Rank 5 counter 1 \n",
      "Rank 5 counter 1 \n",
      "Rank 5 counter 1 \n",
      "Rank 5 counter 0 \n",
      "Rank 5 counter 0 \n",
      "Rank 5 counter 1 \n",
      "Rank 5 counter 0 \n",
      "5 send displace 0 \n",
      "5 send displace 1 \n",
      "5 send displace 2 \n",
      "5 send displace 3 \n",
      "5 send displace 3 \n",
      "5 send displace 3 \n",
      "5 send displace 4 \n",
      "1 send displace 0 \n",
      "1 send displace 0 \n",
      "1 send displace 1 \n",
      "1 send displace 2 \n",
      "1 send displace 3 \n",
      "1 send displace 3 \n",
      "1 send displace 3 \n",
      "7 send displace 0 \n",
      "7 send displace 0 \n",
      "7 send displace 1 \n",
      "7 send displace 1 \n",
      "7 send displace 2 \n",
      "7 send displace 2 \n",
      "7 send displace 3 \n",
      "3 send displace 1 \n",
      "3 send displace 2 \n",
      "3 send displace 2 \n",
      "3 send displace 2 \n",
      "3 send displace 3 \n",
      "3 send displace 3 \n",
      "3 send displace 4 \n",
      "2 send displace 0 \n",
      "2 send displace 0 \n",
      "2 send displace 2 \n",
      "2 send displace 3 \n",
      "2 send displace 3 \n",
      "2 send displace 3 \n",
      "2 send displace 4 \n",
      "0 send displace 0 \n",
      "0 send displace 2 \n",
      "0 send displace 3 \n",
      "0 send displace 3 \n",
      "0 send displace 4 \n",
      "0 send displace 4 \n",
      "0 send displace 4 \n",
      "rank 4 recvbuf 1 \n",
      "rank 4 recvbuf 1 \n",
      "rank 4 recvbuf 0 \n",
      "rank 4 recvbuf 1 \n",
      "rank 4 recvbuf 0 \n",
      "rank 4 recvbuf 0 \n",
      "rank 4 recvbuf 0 \n",
      "rank 4 recvbuf 1 \n",
      "rank 4 total recv buf 4 \n",
      "rank 6 recvbuf 0 \n",
      "rank 6 recvbuf 0 \n",
      "rank 6 recvbuf 1 \n",
      "rank 6 recvbuf 1 \n",
      "rank 6 recvbuf 1 \n",
      "rank 6 recvbuf 1 \n",
      "rank 6 recvbuf 1 \n",
      "rank 6 recvbuf 1 \n",
      "rank 6 total recv buf 6 \n",
      "rank 0 recvbuf 0 \n",
      "rank 0 recvbuf 0 \n",
      "rank 0 recvbuf 0 \n",
      "rank 0 recvbuf 1 \n",
      "rank 0 recvbuf 1 \n",
      "rank 0 recvbuf 0 \n",
      "rank 0 recvbuf 1 \n",
      "rank 0 recvbuf 0 \n",
      "rank 0 total recv buf 3 \n",
      "rank 5 recvbuf 0 \n",
      "rank 5 recvbuf 0 \n",
      "rank 5 recvbuf 0 \n",
      "rank 5 recvbuf 0 \n",
      "rank 5 recvbuf 1 \n",
      "rank 5 recvbuf 0 \n",
      "rank 5 recvbuf 1 \n",
      "rank 5 recvbuf 0 \n",
      "rank 5 total recv buf 2 \n",
      "rank 2 recvbuf 1 \n",
      "rank 2 recvbuf 1 \n",
      "rank 2 recvbuf 2 \n",
      "rank 2 recvbuf 0 \n",
      "rank 2 recvbuf 0 \n",
      "rank 2 recvbuf 1 \n",
      "rank 2 recvbuf 0 \n",
      "rank 2 recvbuf 1 \n",
      "rank 2 total recv buf 6 \n",
      "rank 7 recvbuf 0 \n",
      "rank 7 recvbuf 1 \n",
      "rank 7 recvbuf 0 \n",
      "rank 7 recvbuf 0 \n",
      "rank 7 recvbuf 1 \n",
      "rank 7 recvbuf 0 \n",
      "rank 7 recvbuf 0 \n",
      "rank 7 recvbuf 1 \n",
      "rank 7 total recv buf 3 \n",
      "rank 3 recvbuf 0 \n",
      "rank 3 recvbuf 1 \n",
      "rank 3 recvbuf 1 \n",
      "rank 3 recvbuf 0 \n",
      "rank 3 recvbuf 0 \n",
      "rank 3 recvbuf 1 \n",
      "rank 3 recvbuf 1 \n",
      "rank 3 recvbuf 0 \n",
      "rank 3 total recv buf 4 \n",
      "rank 1 recvbuf 2 \n",
      "rank 1 recvbuf 0 \n",
      "rank 1 recvbuf 0 \n",
      "rank 1 recvbuf 1 \n",
      "rank 1 recvbuf 0 \n",
      "rank 1 recvbuf 1 \n",
      "rank 1 recvbuf 0 \n",
      "rank 1 recvbuf 0 \n",
      "rank 1 total recv buf 4 \n",
      "1 recv displace 2 \n",
      "1 recv displace 2 \n",
      "1 recv displace 2 \n",
      "1 recv displace 3 \n",
      "1 recv displace 3 \n",
      "1 recv displace 4 \n",
      "1 recv displace 4 \n",
      "3 recv displace 0 \n",
      "3 recv displace 1 \n",
      "3 recv displace 2 \n",
      "3 recv displace 2 \n",
      "3 recv displace 2 \n",
      "3 recv displace 3 \n",
      "3 recv displace 4 \n",
      "5 recv displace 0 \n",
      "5 recv displace 0 \n",
      "5 recv displace 0 \n",
      "5 recv displace 0 \n",
      "5 recv displace 1 \n",
      "5 recv displace 1 \n",
      "5 recv displace 2 \n",
      "7 recv displace 0 \n",
      "7 recv displace 1 \n",
      "7 recv displace 1 \n",
      "7 recv displace 1 \n",
      "7 recv displace 2 \n",
      "7 recv displace 2 \n",
      "7 recv displace 2 \n",
      "2 recv displace 1 \n",
      "2 recv displace 2 \n",
      "2 recv displace 4 \n",
      "2 recv displace 4 \n",
      "2 recv displace 4 \n",
      "2 recv displace 5 \n",
      "2 recv displace 5 \n",
      "0 recv displace 0 \n",
      "0 recv displace 0 \n",
      "0 recv displace 0 \n",
      "0 recv displace 1 \n",
      "0 recv displace 2 \n",
      "0 recv displace 2 \n",
      "0 recv displace 3 \n",
      "4 recv displace 1 \n",
      "4 recv displace 2 \n",
      "4 recv displace 2 \n",
      "4 recv displace 3 \n",
      "4 recv displace 3 \n",
      "4 recv displace 3 \n",
      "4 recv displace 3 \n",
      "6 recv displace 0 \n",
      "6 recv displace 0 \n",
      "6 recv displace 1 \n",
      "6 recv displace 2 \n",
      "6 recv displace 3 \n",
      "6 recv displace 4 \n",
      "6 recv displace 5 \n",
      "rank 5 semi-sorted num 20 \n",
      "rank 5 semi-sorted num 22 \n",
      "rank 6 semi-sorted num 26 \n",
      "rank 6 semi-sorted num 27 \n",
      "rank 6 semi-sorted num 24 \n",
      "rank 6 semi-sorted num 27 \n",
      "rank 6 semi-sorted num 26 \n",
      "rank 6 semi-sorted num 26 \n",
      "rank 3 semi-sorted num 12 \n",
      "rank 3 semi-sorted num 13 \n",
      "rank 3 semi-sorted num 13 \n",
      "rank 3 semi-sorted num 14 \n",
      "rank 4 semi-sorted num 19 \n",
      "rank 4 semi-sorted num 17 \n",
      "rank 4 semi-sorted num 18 \n",
      "rank 4 semi-sorted num 19 \n",
      "rank 0 semi-sorted num 3 \n",
      "rank 0 semi-sorted num 2 \n",
      "rank 0 semi-sorted num 3 \n",
      "rank 2 semi-sorted num 9 \n",
      "rank 2 semi-sorted num 10 \n",
      "rank 2 semi-sorted num 9 \n",
      "rank 2 semi-sorted num 11 \n",
      "rank 2 semi-sorted num 8 \n",
      "rank 2 semi-sorted num 9 \n",
      "rank 7 semi-sorted num 31 \n",
      "rank 7 semi-sorted num 28 \n",
      "rank 7 semi-sorted num 31 \n",
      "rank 1 semi-sorted num 6 \n",
      "rank 1 semi-sorted num 7 \n",
      "rank 1 semi-sorted num 6 \n",
      "rank 1 semi-sorted num 7 \n",
      "Before sort: \n",
      "7 6 9 19 17 31 10 12 9 13 26 11 18 27 3 6 28 2 20 24 27 8 7 13 22 26 14 3 19 31 9 26 \n",
      "After sort: \n",
      "2 3 3 6 6 7 7 8 9 9 9 10 11 12 13 13 14 17 18 19 19 20 22 24 26 26 26 27 27 28 31 31 "
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/bucket2.c -o ~/bucket2\n",
    "!mpirun -np 8 --map-by core:OVERSUBSCRIBE ~/bucket2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> N-Body Problem </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Fundamental settings for most, if not all, of computational simulation problems: **\n",
    "\n",
    "- Given a space\n",
    "- Given a group of entities whose activities are (often) bounded within this space\n",
    "- Given a set of equation that governs how these entities react to one another and to attributes of the containing space\n",
    "- Simulate how these reactions impact all entities and the entire space overtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Computation requires parallelization\n",
    "- Experimental spaces are simulated at massive scale (millions of entities)\n",
    "- Individual time steps are significantly smaller than the total simulation time. \n",
    "- Time complexity can be reduced by approximating a cluster of distant bodies as a single distant body with mass sited at the center of the mass of the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/07/mass-bodies.png\" width=\"700\"/> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Barnes-Hut Algorithm (2-D)\n",
    "\n",
    "Start with whole region in which one square contains the bodies (or particles).\n",
    "- First, this cube is divided into four subregions.\n",
    "- If a subregion contains no particles, it is deleted from further consideration.\n",
    "- If a subregion contains one body, it is retained.\n",
    "- If a subregion contains more than one body, it is recursively divided until every subregion contains one body.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Create an quadtree  a tree with up to four edges from each node\n",
    "- The leaves represent cells each containing one body.\n",
    "- After the tree has been constructed, the total mass and center of mass of the subregion is stored at each node.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/07/barnes-hut.png\" width=\"700\"/> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Orthogonal Recursive Bisection\n",
    "\n",
    "- First, a vertical line found that divides area into two areas each with equal number of bodies. \n",
    "- For each area, a horizontal line found that divides it into two areas, each with equal number of bodies. \n",
    "- Repeated as required. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/07/orthogonal.png\" width=\"400\"/> \n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
