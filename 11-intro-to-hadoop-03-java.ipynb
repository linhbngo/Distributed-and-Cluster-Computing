{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Introduction to Hadoop MapReduce </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First principle of optimizing Hadoop workflow: **Reduce data movement in the shuffle phase**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ hdfs dfs -mkdir intro-to-hadoop\n",
    "$ cp -R /local/repository/codes .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to compile a Java source code that utilizes the Hadoop MapReduce libraries\n",
    "\n",
    "```\n",
    "$ cat codes/compileMR.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/linhbngo/cluster-template/blob/hadoop/codes/airlines/avgDepartureDelay.java"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "Run a *jar* file on Hadoop\n",
    "\n",
    "```\n",
    "$ bash ./codes/compileMR.sh codes/airlines/avgDepartureDelay\n",
    "$ yarn jar codes/airlines/avgDepartureDelay.jar avgDepartureDelay /repository/airlines/data/ avg-output-1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "18/11/08 11:31:38 INFO mapreduce.Job: Job job_1541649618909_0006 completed successfully\n",
    "18/11/08 11:31:39 INFO mapreduce.Job: Counters: 54\n",
    "        File System Counters\n",
    "                FILE: Number of bytes read=1092623207\n",
    "                FILE: Number of bytes written=2207795995\n",
    "                FILE: Number of read operations=0\n",
    "                FILE: Number of large read operations=0\n",
    "                FILE: Number of write operations=0\n",
    "                HDFS: Number of bytes read=12038926861\n",
    "                HDFS: Number of bytes written=157\n",
    "                HDFS: Number of read operations=293\n",
    "                HDFS: Number of large read operations=0\n",
    "                HDFS: Number of write operations=2\n",
    "        Job Counters\n",
    "                Launched map tasks=96\n",
    "                Launched reduce tasks=1\n",
    "                Data-local map tasks=94\n",
    "                Rack-local map tasks=2\n",
    "                Total time spent by all maps in occupied slots (ms)=38760984\n",
    "                Total time spent by all reduces in occupied slots (ms)=13601844\n",
    "                Total time spent by all map tasks (ms)=717796\n",
    "                Total time spent by all reduce tasks (ms)=125943\n",
    "                Total vcore-milliseconds taken by all map tasks=717796\n",
    "                Total vcore-milliseconds taken by all reduce tasks=125943\n",
    "                Total megabyte-milliseconds taken by all map tasks=39691247616\n",
    "                Total megabyte-milliseconds taken by all reduce tasks=13928288256\n",
    "        Map-Reduce Framework\n",
    "                Map input records=123534991\n",
    "                Map output records=121232833\n",
    "                Map output bytes=850157535\n",
    "                Map output materialized bytes=1092623777\n",
    "                Input split bytes=13440\n",
    "                Combine input records=0\n",
    "                Combine output records=0\n",
    "                Reduce input groups=29\n",
    "                Reduce shuffle bytes=1092623777\n",
    "                Reduce input records=121232833\n",
    "                Reduce output records=29\n",
    "                Spilled Records=242465666\n",
    "                Shuffled Maps =96\n",
    "                Failed Shuffles=0\n",
    "                Merged Map outputs=96\n",
    "                GC time elapsed (ms)=88962\n",
    "                CPU time spent (ms)=2512020\n",
    "                Physical memory (bytes) snapshot=317483470848\n",
    "                Virtual memory (bytes) snapshot=4810731032576\n",
    "                Total committed heap usage (bytes)=365535166464\n",
    "                Peak Map Physical memory (bytes)=3499929600\n",
    "                Peak Map Virtual memory (bytes)=49104142336\n",
    "                Peak Reduce Physical memory (bytes)=4383043584\n",
    "                Peak Reduce Virtual memory (bytes)=97246007296\n",
    "        Shuffle Errors\n",
    "                BAD_ID=0\n",
    "                CONNECTION=0\n",
    "                IO_ERROR=0\n",
    "                WRONG_LENGTH=0\n",
    "                WRONG_MAP=0\n",
    "                WRONG_REDUCE=0\n",
    "        File Input Format Counters\n",
    "                Bytes Read=12038913421\n",
    "        File Output Format Counters\n",
    "                Bytes Written=157\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is being passed from Map to Reduce?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common optimization approaches:\n",
    "\n",
    "1. Additional combiner function \n",
    "2. In-mapper reduction of key/value pairs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Combiner function\n",
    "\n",
    "https://github.com/linhbngo/cluster-template/blob/hadoop/codes/airlines/avgDepartureDelayVersionTwo.java"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Excercise \n",
    "\n",
    "- Compile and run *avgDepatureDelayVersionTwo.java* on the Hadoop cluster\n",
    "- Examine its output information and compare shuffle data size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-mapper reduction of Key/Value pairs\n",
    "\n",
    "https://github.com/linhbngo/cluster-template/blob/hadoop/codes/airlines/avgDepartureDelayVersionThree.java"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Excercise \n",
    "\n",
    "- Compile and run *avgDepatureDelayVersionTwo.java* on the Hadoop cluster\n",
    "- Examine its output information and compare shuffle data size. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
