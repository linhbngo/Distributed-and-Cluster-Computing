{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>Synchronous Computing</center>\n",
    "### <center> Linh B. Ngo </center>\n",
    "### <center> CPSC 3620 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Synchronous Computation </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In a (fully) synchronous computation, all the processes synchronized at regular points, usually to exchange data or to make sure that every process has gone through the same set of procedures (to update their own data) before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/mpi4py/nobarrier.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/mpi4py/nobarrier.py\n",
    "#!/usr/bin/env python\n",
    "# nobarrier.py\n",
    "import time\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    time.sleep(5)\n",
    "print (\"process \" + str(rank) + \" is here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 2 is here\n",
      "process 3 is here\n",
      "process 1 is here\n",
      "process 0 is here\n"
     ]
    }
   ],
   "source": [
    "!chmod 755 codes/mpi4py/nobarrier.py\n",
    "!module load gcc/5.3.0 openmpi/1.10.3; mpirun -np 4 --mca mpi_cuda_support 0 codes/mpi4py/nobarrier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/mpi4py/barrier.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/mpi4py/barrier.py\n",
    "#!/usr/bin/env python\n",
    "# barrier.py\n",
    "import time\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "if rank == 0:\n",
    "    time.sleep(5)\n",
    "comm.Barrier()\n",
    "print (\"process \" + str(rank) + \" is here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 2 is here\r\n",
      "process 3 is here\r\n",
      "process 0 is here\r\n",
      "process 1 is here\r\n"
     ]
    }
   ],
   "source": [
    "!chmod 755 codes/mpi4py/barrier.py\n",
    "!module load gcc/5.3.0 openmpi/1.10.3; mpirun -np 4 --mca mpi_cuda_support 0 codes/mpi4py/barrier.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Barrier </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- A basic mechanism for synchronizing processes - inserted at the point in each process where it must wait\n",
    "- All processes can continue from this point when all the processes have reached it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Comm.Barrier()\n",
    "\n",
    "Parameters:\n",
    "- Comm (MPI comm) â€“ communicator on which we are to block processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/08/treebarrier1.png\" width=\"700\"/> \n",
    "<sub>Wilkinson, Barry, and Michael Allen. Parallel programming. 2nd Ed. 2003. </sub>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/08/treebarrier2.png\" width=\"700\"/> \n",
    "<sub>Wilkinson, Barry, and Michael Allen. Parallel programming. 2nd Ed. 2003. </sub>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/08/butterflybarrier1.png\" width=\"700\"/> \n",
    "<sub>Wilkinson, Barry, and Michael Allen. Parallel programming. 2nd Ed. 2003. </sub>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Prefix Sum Problem </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Given a list of numbers, $x_0, ..., x_{n-1}$, compute all partial summations, i.e:\n",
    "- $x_0 + x_1$\n",
    "- $x_0 + x_1 + x_2$\n",
    "- $x_0 + x_1 + x_2 + x_3$\n",
    "- $x_0 + x_1 + x_2 + x_3 + x_4$\n",
    "- ...\n",
    "\n",
    "Widely studied with practical applications in process allocation, data compaction, sorting, and polynomial evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/08/prefixsum.png\" width=\"700\"/> \n",
    "<sub>Wilkinson, Barry, and Michael Allen. Parallel programming. 2nd Ed. 2003. </sub>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/mpi4py/prefixsum.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/mpi4py/prefixsum.py\n",
    "#!/usr/bin/env python\n",
    "# prefixsum.py\n",
    "import numpy as np; import math; from mpi4py import MPI;\n",
    "comm = MPI.COMM_WORLD; rank = comm.Get_rank(); size = comm.Get_size(); N = 16\n",
    "local_nums = np.zeros(int(N/size), dtype=\"int\")\n",
    "recv_sum = np.zeros(1, dtype=\"int\")\n",
    "local_sums = np.zeros(int(N/size), dtype=\"int\")\n",
    "for i in range(0,int(N/size)):\n",
    "    local_nums[i] = rank * int(N/size) + i\n",
    "    local_sums[i] += np.sum(local_nums[0:(i+1)])\n",
    "\n",
    "print(\"Process \", rank, \" has initial local numbers: \", local_nums);\n",
    "print(\"Process \", rank, \" has initial local prefix sums: \", local_sums)\n",
    "comm.Barrier()\n",
    "for i in range(0, int(math.log2(size))):\n",
    "    distance = int(math.pow(2,i))\n",
    "    if (rank < (size - distance)):\n",
    "        comm.Send(local_sums[int(N/size) - 1], dest = rank + distance, tag = 0)\n",
    "    if (rank >= distance):\n",
    "        status = MPI.Status()\n",
    "        comm.Recv(recv_sum, source = rank - distance, tag = 0, status = status);\n",
    "        for j in range(0,int(N/size)):\n",
    "            local_sums[j] += recv_sum[0]\n",
    "comm.Barrier()\n",
    "print(\"Process \", rank, \" has final prefix sums: \", local_sums)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process  0  has initial local numbers:  [0 1 2 3]\r\n",
      "Process  0  has initial local prefix sums:  [0 1 3 6]\r\n",
      "Process  0  has final prefix sums:  [0 1 3 6]\r\n",
      "Process  1  has initial local numbers:  [4 5 6 7]\r\n",
      "Process  1  has initial local prefix sums:  [ 4  9 15 22]\r\n",
      "Process  1  has final prefix sums:  [10 15 21 28]\r\n",
      "Process  2  has initial local numbers:  [ 8  9 10 11]\r\n",
      "Process  2  has initial local prefix sums:  [ 8 17 27 38]\r\n",
      "Process  2  has final prefix sums:  [36 45 55 66]\r\n",
      "Process  3  has initial local numbers:  [12 13 14 15]\r\n",
      "Process  3  has initial local prefix sums:  [12 25 39 54]\r\n",
      "Process  3  has final prefix sums:  [ 78  91 105 120]\r\n"
     ]
    }
   ],
   "source": [
    "!chmod 755 codes/mpi4py/prefixsum.py\n",
    "!module load gcc/5.3.0 openmpi/1.10.3; mpirun -np 4 --mca mpi_cuda_support 0 codes/mpi4py/prefixsum.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (Anaconda)",
   "language": "python",
   "name": "anaconda_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
