{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Introduction to Spark In-memmory Computing via Spark Scala</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "SSH into CloudLab.\n",
    "\n",
    "```\n",
    "$ ssh clnode218.clemson.cloudlab.us\n",
    "```\n",
    "\n",
    "From inside the terminal, open Spark's interactive shell\n",
    "\n",
    "```\n",
    "$ spark-shell --master yarn --driver-memory 1G --executor-memory 10G --num-executors 10 --verbose --conf \"spark.port.maxRetries=40\" --packages com.databricks:spark-csv_2.11:1.5.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View entry points inside the shell\n",
    "\n",
    "```\n",
    "scala> sc\n",
    "scala> spark.sqlContext\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Air Traffic Data\n",
    "\n",
    "Original data from [Burreau of Transportation Statistics](https://www.transtats.bts.gov/Fields.asp?Table_ID=236) that provides air carrier ontime performance data from 1987 to 2008. Processed data comes from [American Statistics Association](http://stat-computing.org/dataexpo/2009/the-data.html). \n",
    "- More than 120 millions entries\n",
    "- More than 12GB in size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```\n",
    "scala> val airlines = sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"hdfs:///repository/airlines/data\").cache()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Excercises:\n",
    "\n",
    "- Time how long it takes to count `airlines`\n",
    "- Time and count again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```\n",
    "scala> airlines.printSchema\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert RDD to SQL table:\n",
    "\n",
    "```\n",
    "scala> airlines.registerTempTable(\"airlines\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all unique carriers\n",
    "\n",
    "```\n",
    "scala> val uniqueAirline = spark.sqlContext.sql(\"SELECT DISTINCT UniqueCarrier FROM airlines\")\n",
    "scala> uniqueAirline.show\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many flights per unique carriers\n",
    "\n",
    "```\n",
    "scala>val carrierFlightCount = spark.sqlContext.sql(\"SELECT UniqueCarrier, COUNT(UniqueCarrier) AS FlightCount FROM airlines GROUP BY UniqueCarrier\")\n",
    "scala> spark.time(carrierFlightCount.show())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Display carriers' full names:\n",
    "\n",
    "```\n",
    "scala> val carriers = spark.sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(\"hdfs:///repository/airlines/metadata/carriers.csv\").cache\n",
    "scala> carriers.registerTempTable(\"carriers\")\n",
    "scala> val carrierFlightCountFull = spark.sqlContext.sql(\"SELECT c.Description, a.UniqueCarrier, COUNT(a.UniqueCarrier) AS FlightCount FROM airlines AS a INNER JOIN carriers AS c ON c.Code = a.UNiqueCarrier GROUP BY a.UniqueCarrier, c.Description ORDER BY a.UniqueCarrier\")\n",
    "scala> spark.time(carrierFlightCountFull.show)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the averaged departure delay time for each airline?\n",
    "\n",
    "```\n",
    "scala> val avgDepDelay = spark.sqlContext.sql(\"SELECT FIRST(c.Description), FIRST(a.UniqueCarrier), AVG(a.DepDelay) AS AvgDepDelay FROM airlines AS a INNER JOIN carriers AS c ON c.Code = a.UniqueCarrier GROUP BY a.UniqueCarrier ORDER BY a.UniqueCarrier\")\n",
    "scala> spark.time(avgDepDelay.show)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
