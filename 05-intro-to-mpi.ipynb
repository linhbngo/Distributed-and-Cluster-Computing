{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>Introduction to Message Passing Interface (MPI)</center>\n",
    "### <center> Linh B. Ngo </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center>Message Passing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Processes communicate via messages\n",
    "- Messages can be\n",
    "    - Raw data to be used in actual calculations\n",
    "    - Signals and acknowledgements for the receiving processes regarding the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center>History of MPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Early 80s:**\n",
    "- Various message passing environments were developed\n",
    "- Many similar fundamental concepts\n",
    "- N-cube (Caltech), P4 (Argonne), PICL and PVM (Oakridge), LAM (Ohio SC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** 1992: **\n",
    "- More than 80 reseachers from different institutions in US and Europe agreed to develop and implement a common standard for message passing\n",
    "- First meeting colocated with Supercomputing 1992"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** After finalization: **\n",
    "- MPI becomes the *de-factor* standard for distributed memory parallel programming\n",
    "- Available on every popular operating system and architecture\n",
    "- Interconnect manufacturers commonly provide MPI implementations optimized for their hardware\n",
    "- MPI standard defines interfaces for C, C++, and Fortran\n",
    "    - Language bindings available for many popular languages (quality varies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** 1994: MPI-1 **\n",
    "- Communicators\n",
    "    - Information about the runtime environments\n",
    "    - Creation of customized topologies\n",
    "- Point-to-point communication\n",
    "    - Send and receive messages\n",
    "    - Blocking and non-blocking variations\n",
    "- Collectives\n",
    "    - Broadcast and reduce\n",
    "    - Gather and scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** 1998: MPI-2 **\n",
    "- One-sided communication (non-blocking)\n",
    "    - Get & Put (remote memory access)\n",
    "- Dynamic process management\n",
    "    - Spawn\n",
    "- Parallel I/O\n",
    "    - Multiple readers and writers for a single file\n",
    "    - Requires file-system level support (LustreFS, PVFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** 2012: MPI-3 **\n",
    "- Revised remote-memory access semantic\n",
    "- Fault tolerance model\n",
    "- Non-blocking collective communication\n",
    "- Access to internal variables, states, and counters for performance evaluation purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Set up MPI on Palmetto for C/C++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Open a terminal and run the following commands. For `ssh-keygen`, hit `Enter` for everything and don't put in a password when asked. \n",
    "\n",
    "```\n",
    "$ cd ~\n",
    "$ sudo yum -y group install \"Development Tools\"\n",
    "$ wget https://download.open-mpi.org/release/open-mpi/v3.1/openmpi-3.1.2.tar.gz\n",
    "$ tar xzf openmpi-3.1.2.tar.gz\n",
    "$ cd openmpi-3.1.2\n",
    "$ ./configure --prefix=/opt/openmpi/3.1.2\n",
    "$ sudo make\n",
    "$ sudo make all install\n",
    "$ echo \"export PATH='$PATH:/opt/openmpi/3.1.2/bin'\" >> ~/.bashrc\n",
    "$ echo \"export LD_LIBRARY_PATH='$LD_LIBRARY_PATH:/opt/openmpi/3.1.2/lib/'\" >> ~/.bashrc\n",
    "$ source ~/.bashrc\n",
    "$ cd ~\n",
    "$ ssh-keygen\n",
    "$ ssh-copy-id localhost\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "After the above steps are completed successfully, you will need to return to the VM, run the command `source ~/.bashrc` and restart the Jupyter notebook server. \n",
    "\n",
    "The next cells can be run from inside the Jupyter notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/first.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/first.c\n",
    "#include <stdio.h>\n",
    "#include <sys/utsname.h>\n",
    "#include <mpi.h>\n",
    "int main(int argc, char *argv[]){\n",
    "  MPI_Init(&argc, &argv);\n",
    "  struct utsname uts;\n",
    "  uname (&uts);\n",
    "  printf(\"My process is on node %s.\\n\", uts.nodename);\n",
    "  MPI_Finalize();\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My process is on node localhost.localdomain.\r\n",
      "My process is on node localhost.localdomain.\r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/first.c -o ~/first\n",
    "!mpirun -np 2 ~/first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> The working of MPI in a nutshell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- All processes are launched at the beginning of the program execution\n",
    "    - The number of processes are user-speficied\n",
    "    - Typically, this number is matched to the total number of cores available across the entire cluster\n",
    "- All processes have their own memory space and have access to the same source codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Basic parameters available to individual processes: **\n",
    "```\n",
    "MPI.COMM_WORLD\n",
    "MPI_Comm_rank()\n",
    "MPI_Comm_size()\n",
    "MPI_Get_processor_name()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- MPI defines **communicator** groups for point-to-point and collective communications\n",
    "    - Unique IDs (**rank**) are defined for individual processes within a communicator group\n",
    "    - Communications are performed based on these IDs\n",
    "    - Default **global communication** (MPI_COMM_WORLD) contains all processes\n",
    "    - For $N$ processes, ranks go from $0$ to $N-1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/hello.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/hello.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "  int size;\n",
    "  int my_rank; \n",
    "  char proc_name[MPI_MAX_PROCESSOR_NAME];\n",
    "  int proc_name_len;\n",
    "    \n",
    "  /* Initialize the MPI environment */\n",
    "  MPI_Init(&argc, &argv);\n",
    "  \n",
    "  /* Get the number of processes */\n",
    "  MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "  /* Get the rank of the process */\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "\n",
    "  /* Get the name of the processor */\n",
    "  MPI_Get_processor_name(proc_name, &proc_name_len);\n",
    "\n",
    "  /* Print off a hello world message */\n",
    "  printf(\"Hello world from processor %s, rank %d out of %d processes\\n\",\n",
    "           proc_name, my_rank, size);\n",
    "\n",
    "  /* Finalize the MPI environment. */\n",
    "  MPI_Finalize();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world from processor localhost.localdomain, rank 0 out of 2 processes\r\n",
      "Hello world from processor localhost.localdomain, rank 1 out of 2 processes\r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/hello.c -o ~/hello\n",
    "!mpirun -np 2 ~/hello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Important\n",
    "\n",
    "On many VM, you might not have enough physical cores located to the VM in VirtualBox. To enable the simulation of multiple processes, you need to add `--map-by core:OVERSUBSCRIBE` to your `mpirun` commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "There are not enough slots available in the system to satisfy the 8 slots\n",
      "that were requested by the application:\n",
      "  /home/lngo/hello\n",
      "\n",
      "Either request fewer slots for your application, or make more slots available\n",
      "for use.\n",
      "--------------------------------------------------------------------------\n",
      "Hello world from processor localhost.localdomain, rank 3 out of 8 processes\n",
      "Hello world from processor localhost.localdomain, rank 6 out of 8 processes\n",
      "Hello world from processor localhost.localdomain, rank 7 out of 8 processes\n",
      "Hello world from processor localhost.localdomain, rank 0 out of 8 processes\n",
      "Hello world from processor localhost.localdomain, rank 1 out of 8 processes\n",
      "Hello world from processor localhost.localdomain, rank 4 out of 8 processes\n",
      "Hello world from processor localhost.localdomain, rank 5 out of 8 processes\n",
      "Hello world from processor localhost.localdomain, rank 2 out of 8 processes\n"
     ]
    }
   ],
   "source": [
    "!mpirun -np 8 ~/hello\n",
    "!mpirun -np 8 --map-by core:OVERSUBSCRIBE ~/hello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Ranks are used to enforce execution/exclusion of code segments within the original source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/evenodd.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/evenodd.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "  int my_rank; \n",
    "    \n",
    "  /* Initialize the MPI environment */\n",
    "  MPI_Init(&argc, &argv);\n",
    "\n",
    "  /* Get the rank of the process */\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "\n",
    "  if (my_rank % 2 == 1) {\n",
    "    printf (\"Process %d is even \\n\", my_rank);\n",
    "  } else {\n",
    "    printf (\"Process %d is odd \\n\", my_rank);\n",
    "  }\n",
    "  MPI_Finalize();\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 2 is odd \r\n",
      "Process 3 is even \r\n",
      "Process 0 is odd \r\n",
      "Process 1 is even \r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/evenodd.c -o ~/evenodd\n",
    "!mpirun -np 4 --map-by core:OVERSUBSCRIBE ~/evenodd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Ranks and size are used means to calculate and distributed workload (data) among the processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/rank_size.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/rank_size.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "  int size;\n",
    "  int my_rank; \n",
    "  int A[16] = {2,13,4,3,5,1,0,12,10,8,7,9,11,6,15,14};\n",
    "  int i;\n",
    "    \n",
    "  MPI_Init(&argc, &argv);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "\n",
    "  for (i = 0; i < 16; i++){\n",
    "    if (i % size == my_rank){\n",
    "      printf (\"Process %d has elements %d at index %d \\n\",\n",
    "               my_rank, A[i], i);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  /* Finalize the MPI environment. */\n",
    "  MPI_Finalize();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 2 has elements 4 at index 2 \r\n",
      "Process 2 has elements 0 at index 6 \r\n",
      "Process 2 has elements 7 at index 10 \r\n",
      "Process 2 has elements 15 at index 14 \r\n",
      "Process 3 has elements 3 at index 3 \r\n",
      "Process 3 has elements 12 at index 7 \r\n",
      "Process 3 has elements 9 at index 11 \r\n",
      "Process 3 has elements 14 at index 15 \r\n",
      "Process 0 has elements 2 at index 0 \r\n",
      "Process 0 has elements 5 at index 4 \r\n",
      "Process 0 has elements 10 at index 8 \r\n",
      "Process 0 has elements 11 at index 12 \r\n",
      "Process 1 has elements 13 at index 1 \r\n",
      "Process 1 has elements 1 at index 5 \r\n",
      "Process 1 has elements 8 at index 9 \r\n",
      "Process 1 has elements 6 at index 13 \r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/rank_size.c -o ~/rank_size\n",
    "!mpirun -np 4 ~/rank_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Individual processes rely on communication (message passing) to enforce workflow\n",
    "    - Point-to-point Communication\n",
    "    - Collective Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Point-to-Point: Send and Receive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Original MPI C Syntax: MPI_Send**\n",
    "```\n",
    "int MPI_Send(void *buf, \n",
    "\tint count, \n",
    "\tMPI_Datatype datatype, \n",
    "\tint dest, \n",
    "\tint tag, \n",
    "\tMPI_Comm comm)\n",
    "```\n",
    "\n",
    "- MPI_Datatype may be MPI_BYTE, MPI_PACKED, MPI_CHAR, MPI_SHORT, MPI_INT, MPI_LONG, MPI_FLOAT, MPI_DOUBLE, MPI_LONG_DOUBLE, MPI_UNSIGNED_CHAR\n",
    "- *dest* is the rank of the process the message is sent to\n",
    "- *tag* is an integer identify the message. Programmer is responsible for managing tag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Original MPI C Syntax: MPI_Recv**\n",
    "```\n",
    "int MPI_Recv(\n",
    "\tvoid *buf, \n",
    "\tint count, \n",
    "\tMPI_Datatype datatype, \n",
    "\tint source, \n",
    "\tint tag, \n",
    "\tMPI_Comm comm,\n",
    "\tMPI_Status *status)\n",
    "```\n",
    "\n",
    "- MPI_Datatype may be MPI_BYTE, MPI_PACKED, MPI_CHAR, MPI_SHORT, MPI_INT, MPI_LONG, MPI_FLOAT, MPI_DOUBLE, MPI_LONG_DOUBLE, MPI_UNSIGNED_CHAR\n",
    "- *source* is the rank of the process from which the message was sent.\n",
    "- *tag* is an integer identify the message. MPI_Recv will only place data in the buffer if the tag from MPI_Send matches. The constant MPI_ANY_TAG may be used when the source tag is unknown or not important. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "We want to write an MPI program that exchange the ranks of two processes, 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing codes/openmpi/send_recv.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/send_recv.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "#include <string.h>\n",
    "\n",
    "int main(int argc, char** argv) \n",
    "{\n",
    "  int my_rank;       \n",
    "  int size;             \n",
    "  int tag=0;\n",
    "  int buf,i;\n",
    "  int des1,des2;\n",
    "  MPI_Status status;\n",
    "\n",
    "  MPI_Init(&argc, &argv);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "  /*  set up data */\n",
    "  buf = my_rank; \n",
    "\n",
    "  printf(\"Process %2d has original value %2d \\n\",my_rank,buf);\n",
    "    \n",
    "  if (my_rank == 0){\n",
    "    MPI_Send(&buf,1,MPI_INT,1,tag,MPI_COMM_WORLD);\n",
    "    MPI_Recv(&buf,1,MPI_INT,1,tag,MPI_COMM_WORLD,&status);\n",
    "  }\n",
    "  \n",
    "  if (my_rank == 1){\n",
    "    MPI_Recv(&buf,1,MPI_INT,0,tag,MPI_COMM_WORLD,&status);\n",
    "    MPI_Send(&buf,1,MPI_INT,0,tag,MPI_COMM_WORLD);  \n",
    "  }    \n",
    "  printf(\"Process %2d now has value %2d\\n\",my_rank,buf);\n",
    "\n",
    "  MPI_Finalize();\n",
    "} /* end main */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process  0 has original value  0 \r\n",
      "Process  0 now has value  0\r\n",
      "Process  1 has original value  1 \r\n",
      "Process  1 now has value  0\r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/send_recv.c -o ~/send_recv\n",
    "!mpirun -np 2 ~/send_recv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- What went wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /home/lngo/send_recv_fixed.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/send_recv_fixed.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "#include <string.h>\n",
    "\n",
    "int main(int argc, char** argv) \n",
    "{\n",
    "  int my_rank;       \n",
    "  int size;             \n",
    "  int tag=0;\n",
    "  int buf,i;\n",
    "  int des1,des2;\n",
    "  MPI_Status status;\n",
    "\n",
    "  MPI_Init(&argc, &argv);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "  /*  set up data */\n",
    "  buf = my_rank; \n",
    "\n",
    "  printf(\"Process %2d has original value %2d \\n\",my_rank,buf);\n",
    "    \n",
    "  if (my_rank == 0){\n",
    "    MPI_Send(&buf,1,MPI_INT,1,tag,MPI_COMM_WORLD);\n",
    "    MPI_Recv(&buf,1,MPI_INT,1,tag,MPI_COMM_WORLD,&status);\n",
    "  }\n",
    "  \n",
    "  if (my_rank == 1){\n",
    "    MPI_Recv(&buf,1,MPI_INT,0,tag,MPI_COMM_WORLD,&status);\n",
    "    MPI_Send(&buf,1,MPI_INT,0,tag,MPI_COMM_WORLD);  \n",
    "  }    \n",
    "  printf(\"Process %2d now has value %2d\\n\",my_rank,buf);\n",
    "\n",
    "  MPI_Finalize();\n",
    "} /* end main */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process  0 has original value  0 \r\n",
      "Process  0 now has value  0\r\n",
      "Process  1 has original value  1 \r\n",
      "Process  1 now has value  0\r\n"
     ]
    }
   ],
   "source": [
    "!mpicc ~/send_recv_fixed.c -o ~/send_recv_fixed\n",
    "!mpirun -np 2 ~/send_recv_fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do we do point-to-point communication at scale?\n",
    "- Rely on rank and size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/multi_send_recv.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/multi_send_recv.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "#include <string.h>\n",
    "\n",
    "int main(int argc, char** argv) \n",
    "{\n",
    "  int my_rank;       \n",
    "  int size;             \n",
    "  int tag=0;\n",
    "  int buf,i;\n",
    "  int des1,des2;\n",
    "  MPI_Status status;\n",
    "\n",
    "  MPI_Init(&argc, &argv);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "  /*  set up data */\n",
    "  buf = my_rank; \n",
    "\n",
    "  //printf(\"Process %2d has original value %2d \\n\",my_rank,buf);\n",
    "    \n",
    "  /* set up source and destination */\n",
    "  des1 = (my_rank + 1) % size;\n",
    "  des2 = (my_rank + size - 1) % size;\n",
    "  //printf(\"Process %2d has des1 %2d and des2 %2d\\n\",my_rank,des1,des2);\n",
    "    \n",
    "  /* shift the data n/2 steps */\n",
    "  for (i = 0; i < size/2; i++){\n",
    "    MPI_Send(&buf,1,MPI_INT,des1,tag,MPI_COMM_WORLD);\n",
    "    MPI_Recv(&buf,1,MPI_INT,MPI_ANY_SOURCE,tag,MPI_COMM_WORLD,&status);\n",
    "    MPI_Barrier(MPI_COMM_WORLD);\n",
    "  }\n",
    "\n",
    "  MPI_Send(&buf,1,MPI_INT,des2,tag,MPI_COMM_WORLD);\n",
    "  MPI_Recv(&buf,1,MPI_INT,MPI_ANY_SOURCE,tag,MPI_COMM_WORLD,&status);\n",
    "  \n",
    "  MPI_Barrier(MPI_COMM_WORLD);\n",
    "  printf(\"Process %2d now has value %2d\\n\",my_rank,buf);\n",
    "\n",
    "  /* Shut down MPI */\n",
    "  MPI_Finalize();\n",
    "\n",
    "} /* end main */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process  1 now has value  0\r\n",
      "Process  2 now has value  1\r\n",
      "Process  3 now has value  2\r\n",
      "Process  0 now has value  3\r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/multi_send_recv.c -o ~/multi_send_recv\n",
    "!mpirun -np 4 --map-by core:OVERSUBSCRIBE ~/multi_send_recv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Blocking risks**\n",
    "- Send data larger than available network buffer (Blocking send)\n",
    "- Lost data (or missing sender) leading to receiver hanging indefinitely (Blocking receive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/deadlock_send_recv.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/deadlock_send_recv.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "#include <string.h>\n",
    "\n",
    "int main(int argc, char* argv[]) \n",
    "{\n",
    "  int my_rank;       /* rank of process     */\n",
    "  int size;             /* number of processes */\n",
    "  int source;        /* rank of sender      */\n",
    "  int dest;          /* rank of receiver    */\n",
    "\n",
    "  int tag=0;         /* tag for messages    */\n",
    "  char message[100]; /* storage for message */\n",
    "  MPI_Status status; /* return status for receive */\n",
    "\n",
    "  MPI_Init(&argc, &argv);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "  fprintf(stderr,\"I am here!  ID = %d\\n\", my_rank);\n",
    "  sprintf(message, \"Greetings from process %d!\", my_rank);\n",
    "\n",
    "  if (my_rank == 0) {\n",
    "    dest = 1;\n",
    "    MPI_Recv(message, 100, MPI_CHAR, dest, tag, MPI_COMM_WORLD, &status);\n",
    "    MPI_Send(message, strlen(message)+1, MPI_CHAR, dest, tag, MPI_COMM_WORLD);\n",
    "    printf(\"Process 0 printing:  %s\\n\", message);\n",
    "  }\n",
    "  else { \n",
    "    /* my rank == 1 */\n",
    "    dest = 0;\n",
    "    MPI_Recv(message, 100, MPI_CHAR, dest, tag, MPI_COMM_WORLD, &status);\n",
    "    MPI_Send(message, strlen(message)+1, MPI_CHAR, dest, tag, MPI_COMM_WORLD);\n",
    "    printf(\"Process 1 printing:  %s\\n\", message);\n",
    "  }\n",
    "  \n",
    "  MPI_Finalize();\n",
    "} /* end main */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am here!  ID = 0\n",
      "I am here!  ID = 1\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/deadlock_send_recv.c -o ~/deadlock_send_recv\n",
    "!mpirun -np 2 ~/deadlock_send_recv\n",
    "\n",
    "# The [*] is indicative of a running notebook shell, and if it does not turn into a number, \n",
    "# it means the cell is hanged (deadlocked by MPI).\n",
    "# To escape a hanged cell, click the Square (Stop) button in the tool bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To correct the above error, we need to change the order of the MPI_Recv and MPI_Send in the one of the communication code block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Collective Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Must involve ALL processes within the scope of a communicator\n",
    "- Unexpected behavior, including programming failure, if even one process does not participate\n",
    "- Types of collective communications:\n",
    "    - Synchronization: barrier\n",
    "    - Data movement: broadcast, scatter/gather\n",
    "    - Collective computation (aggregate data to perform computation): Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/05/mpi-collective.png\" width=\"700\"/> \n",
    "<sub> *https://computing.llnl.gov/tutorials/mpi/* </sub>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```\n",
    "int MPI_Bcast(\n",
    "\tvoid *buf, \n",
    "\tint count, \n",
    "\tMPI_Datatype datatype, \n",
    "\tint root, \n",
    "\tMPI_Comm comm);\n",
    "```\n",
    "- Don’t need to specify a TAG or DESTINATION\n",
    "- Must specify the SENDER (root)\n",
    "- Blocking call for all processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/bcast.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/bcast.c\n",
    "#include <stdio.h>\n",
    "#include <mpi.h>\n",
    "\n",
    "int main(int argc, char* argv[]) \n",
    "{\n",
    "  int my_rank;       \n",
    "  int size;\n",
    "  int value;\n",
    "\n",
    "  MPI_Init(&argc, &argv);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank); \n",
    "  \n",
    "  value = my_rank;\n",
    "  printf(\"process %d: Before MPI_Bcast, value is %d\\n\", my_rank, value); \n",
    "\n",
    "  MPI_Bcast(&value, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "  printf(\"process %d: After MPI_Bcast, value is %d\\n\", my_rank, value);\n",
    "\n",
    "  MPI_Finalize();\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 0: Before MPI_Bcast, value is 0\r\n",
      "process 0: After MPI_Bcast, value is 0\r\n",
      "process 3: Before MPI_Bcast, value is 3\r\n",
      "process 2: Before MPI_Bcast, value is 2\r\n",
      "process 2: After MPI_Bcast, value is 0\r\n",
      "process 1: Before MPI_Bcast, value is 1\r\n",
      "process 1: After MPI_Bcast, value is 0\r\n",
      "process 3: After MPI_Bcast, value is 0\r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/bcast.c -o ~/bcast\n",
    "!mpirun -np 4 --map-by core:OVERSUBSCRIBE ~/bcast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Original MPI C Syntax: MPI_Scatter**\n",
    "```\n",
    "int MPI_Scatter(\n",
    "\tvoid *sendbuf, \n",
    "\tint sendcount, \n",
    "\tMPI_Datatype sendtype, \n",
    "\tvoid *recvbuf,\n",
    "\tint recvcnt,\n",
    "\tMPI_Datatype recvtype,\n",
    "\tint root, \n",
    "\tMPI_Comm comm);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/scatter.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/scatter.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "  int size;\n",
    "  int my_rank; \n",
    "  int sendbuf[16] = {2,13,4,3,5,1,0,12,10,8,7,9,11,6,15,14};\n",
    "  int recvbuf[5];\n",
    "  int i;\n",
    "    \n",
    "  MPI_Init(&argc, &argv);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "\n",
    "  MPI_Scatter(&sendbuf, 5, MPI_INT, &recvbuf, 5, MPI_INT, 0, MPI_COMM_WORLD); \n",
    "  for (i = 0; i < 5; i++){\n",
    "    printf (\"Process %d has element %d at index %d in its recvbuf \\n\",\n",
    "               my_rank, recvbuf[i], i);\n",
    "  }\n",
    "\n",
    "  /* Finalize the MPI environment. */\n",
    "  MPI_Finalize();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 0 has element 2 at index 0 in its recvbuf \r\n",
      "Process 0 has element 13 at index 1 in its recvbuf \r\n",
      "Process 0 has element 4 at index 2 in its recvbuf \r\n",
      "Process 0 has element 3 at index 3 in its recvbuf \r\n",
      "Process 0 has element 5 at index 4 in its recvbuf \r\n",
      "Process 1 has element 1 at index 0 in its recvbuf \r\n",
      "Process 1 has element 0 at index 1 in its recvbuf \r\n",
      "Process 1 has element 12 at index 2 in its recvbuf \r\n",
      "Process 1 has element 10 at index 3 in its recvbuf \r\n",
      "Process 1 has element 8 at index 4 in its recvbuf \r\n",
      "Process 2 has element 7 at index 0 in its recvbuf \r\n",
      "Process 2 has element 9 at index 1 in its recvbuf \r\n",
      "Process 2 has element 11 at index 2 in its recvbuf \r\n",
      "Process 2 has element 6 at index 3 in its recvbuf \r\n",
      "Process 2 has element 15 at index 4 in its recvbuf \r\n",
      "Process 3 has element 14 at index 0 in its recvbuf \r\n",
      "Process 3 has element 916566832 at index 1 in its recvbuf \r\n",
      "Process 3 has element 0 at index 2 in its recvbuf \r\n",
      "Process 3 has element 4 at index 3 in its recvbuf \r\n",
      "Process 3 has element 0 at index 4 in its recvbuf \r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/scatter.c -o ~/scatter\n",
    "!mpirun -np 4 --map-by core:OVERSUBSCRIBE ~/scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Original MPI C Syntax: MPI_Gather**\n",
    "```\n",
    "int MPI_Gather(\n",
    "\tvoid *sendbuff, \n",
    "\tint sendcount, \n",
    "\tMPI_Datatype sendtype, \n",
    "\tvoid *recvbuff,\n",
    "\tint recvcnt,\n",
    "\tMPI_Datatype recvtype,\n",
    "\tint root, \n",
    "\tMPI_Comm comm);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/gather.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/gather.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "  int size;\n",
    "  int my_rank; \n",
    "  int sendbuf[2];\n",
    "  int recvbuf[8] = {-1,-1,-1,-1,-1,-1,-1,-1};\n",
    "  int i;\n",
    "    \n",
    "  MPI_Init(&argc, &argv);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "\n",
    "  for (i = 0; i < 2; i++){\n",
    "    sendbuf[i] = my_rank;\n",
    "  }\n",
    "  MPI_Gather(&sendbuf, 2, MPI_INT, &recvbuf, 2, MPI_INT, 0, MPI_COMM_WORLD); \n",
    "  for (i = 0; i < 8; i++){\n",
    "    printf (\"Process %d has element %d at index %d in its recvbuf \\n\",\n",
    "               my_rank, recvbuf[i], i);\n",
    "  }\n",
    "\n",
    "  /* Finalize the MPI environment. */\n",
    "  MPI_Finalize();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 1 has element -1 at index 0 in its recvbuf \r\n",
      "Process 1 has element -1 at index 1 in its recvbuf \r\n",
      "Process 1 has element -1 at index 2 in its recvbuf \r\n",
      "Process 1 has element -1 at index 3 in its recvbuf \r\n",
      "Process 1 has element -1 at index 4 in its recvbuf \r\n",
      "Process 1 has element -1 at index 5 in its recvbuf \r\n",
      "Process 1 has element -1 at index 6 in its recvbuf \r\n",
      "Process 1 has element -1 at index 7 in its recvbuf \r\n",
      "Process 2 has element -1 at index 0 in its recvbuf \r\n",
      "Process 2 has element -1 at index 1 in its recvbuf \r\n",
      "Process 2 has element -1 at index 2 in its recvbuf \r\n",
      "Process 2 has element -1 at index 3 in its recvbuf \r\n",
      "Process 2 has element -1 at index 4 in its recvbuf \r\n",
      "Process 2 has element -1 at index 5 in its recvbuf \r\n",
      "Process 2 has element -1 at index 6 in its recvbuf \r\n",
      "Process 2 has element -1 at index 7 in its recvbuf \r\n",
      "Process 3 has element -1 at index 0 in its recvbuf \r\n",
      "Process 3 has element -1 at index 1 in its recvbuf \r\n",
      "Process 3 has element -1 at index 2 in its recvbuf \r\n",
      "Process 3 has element -1 at index 3 in its recvbuf \r\n",
      "Process 3 has element -1 at index 4 in its recvbuf \r\n",
      "Process 3 has element -1 at index 5 in its recvbuf \r\n",
      "Process 3 has element -1 at index 6 in its recvbuf \r\n",
      "Process 3 has element -1 at index 7 in its recvbuf \r\n",
      "Process 0 has element 0 at index 0 in its recvbuf \r\n",
      "Process 0 has element 0 at index 1 in its recvbuf \r\n",
      "Process 0 has element 1 at index 2 in its recvbuf \r\n",
      "Process 0 has element 1 at index 3 in its recvbuf \r\n",
      "Process 0 has element 2 at index 4 in its recvbuf \r\n",
      "Process 0 has element 2 at index 5 in its recvbuf \r\n",
      "Process 0 has element 3 at index 6 in its recvbuf \r\n",
      "Process 0 has element 3 at index 7 in its recvbuf \r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/gather.c -o ~/gather\n",
    "!mpirun -np 4 --map-by core:OVERSUBSCRIBE ~/gather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Original MPI C Syntax: MPI_Reduce**\n",
    "```\n",
    "int MPI_Reduce(\n",
    "\tvoid *sendbuf, \n",
    "\tvoid *recvbuff,\n",
    "\tint count, \n",
    "\tMPI_Datatype datatype, \n",
    "\tMPI_OP op,\n",
    "\tint root, \n",
    "\tMPI_Comm comm);\n",
    "```\n",
    "- MPI_Op may be MPI_MIN, MPI_MAX, MPI_SUM, MPI_PROD (twelve total)\n",
    "- Programmer may add operations, must be commutative and associative\n",
    "- If count > 1, then operation is performed element-wise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/reduce.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/reduce.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "  int size;\n",
    "  int my_rank; \n",
    "  int rank_sum;\n",
    "  int i;\n",
    "    \n",
    "  MPI_Init(&argc, &argv);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "  \n",
    "  rank_sum = my_rank;\n",
    "\n",
    "  MPI_Reduce(&my_rank, &rank_sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD); \n",
    "  printf (\"The total sum of all ranks at process %d is %d \\n\", my_rank, rank_sum);\n",
    "\n",
    "  /* Finalize the MPI environment. */\n",
    "  MPI_Finalize();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total sum of all ranks at process 2 is 2 \r\n",
      "The total sum of all ranks at process 3 is 3 \r\n",
      "The total sum of all ranks at process 1 is 1 \r\n",
      "The total sum of all ranks at process 0 is 6 \r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/reduce.c -o ~/reduce\n",
    "!mpirun -np 4 --map-by core:OVERSUBSCRIBE ~/reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total sum of all ranks at process 3 is 3 \r\n",
      "The total sum of all ranks at process 5 is 5 \r\n",
      "The total sum of all ranks at process 1 is 1 \r\n",
      "The total sum of all ranks at process 2 is 2 \r\n",
      "The total sum of all ranks at process 6 is 6 \r\n",
      "The total sum of all ranks at process 7 is 7 \r\n",
      "The total sum of all ranks at process 0 is 28 \r\n",
      "The total sum of all ranks at process 4 is 4 \r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/reduce.c -o ~/reduce\n",
    "!mpirun -np 8 --map-by core:OVERSUBSCRIBE ~/reduce"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
