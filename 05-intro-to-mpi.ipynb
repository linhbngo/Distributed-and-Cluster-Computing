{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>Introduction to Message Passing Interface (MPI)</center>\n",
    "### <center> Linh B. Ngo </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center>Message Passing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Processes communicate via messages\n",
    "- Messages can be\n",
    "    - Raw data to be used in actual calculations\n",
    "    - Signals and acknowledgements for the receiving processes regarding the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center>History of MPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Early 80s:**\n",
    "- Various message passing environments were developed\n",
    "- Many similar fundamental concepts\n",
    "- N-cube (Caltech), P4 (Argonne), PICL and PVM (Oakridge), LAM (Ohio SC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** 1992: **\n",
    "- More than 80 reseachers from different institutions in US and Europe agreed to develop and implement a common standard for message passing\n",
    "- First meeting colocated with Supercomputing 1992"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** After finalization: **\n",
    "- MPI becomes the *de-factor* standard for distributed memory parallel programming\n",
    "- Available on every popular operating system and architecture\n",
    "- Interconnect manufacturers commonly provide MPI implementations optimized for their hardware\n",
    "- MPI standard defines interfaces for C, C++, and Fortran\n",
    "    - Language bindings available for many popular languages (quality varies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** 1994: MPI-1 **\n",
    "- Communicators\n",
    "    - Information about the runtime environments\n",
    "    - Creation of customized topologies\n",
    "- Point-to-point communication\n",
    "    - Send and receive messages\n",
    "    - Blocking and non-blocking variations\n",
    "- Collectives\n",
    "    - Broadcast and reduce\n",
    "    - Gather and scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** 1998: MPI-2 **\n",
    "- One-sided communication (non-blocking)\n",
    "    - Get & Put (remote memory access)\n",
    "- Dynamic process management\n",
    "    - Spawn\n",
    "- Parallel I/O\n",
    "    - Multiple readers and writers for a single file\n",
    "    - Requires file-system level support (LustreFS, PVFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** 2012: MPI-3 **\n",
    "- Revised remote-memory access semantic\n",
    "- Fault tolerance model\n",
    "- Non-blocking collective communication\n",
    "- Access to internal variables, states, and counters for performance evaluation purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Set up MPI on Palmetto for C/C++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Open a terminal and run the following commands:\n",
    "\n",
    "```\n",
    "$ cd ~\n",
    "$ wget https://download.open-mpi.org/release/open-mpi/v3.1/openmpi-3.1.2.tar.gz\n",
    "$ tar xzf openmpi-3.1.2.tar.gz\n",
    "$ cd openmpi-3.1.2\n",
    "$ ./configure --prefix=/opt/openmpi/3.1.2\n",
    "$ sudo make\n",
    "$ sudo make all install\n",
    "$ echo \"export PATH='$PATH:/opt/openmpi/3.1.2/bin'\" >> ~/.bashrc\n",
    "$ echo \"export LD_LIBRARY_PATH='$LD_LIBRARY_PATH:/opt/openmpi/3.1.2/lib/'\" >> ~/.bashrc\n",
    "$ source ~/.bashrc\n",
    "$ cd ~\n",
    "$ ssh-copy-id localhost\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "After the above steps are completed successfully, you will need to return to the VM and restart the Jupyter notebook server. \n",
    "\n",
    "The next cells can be run from inside the Jupyter notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing codes/openmpi/hello.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/first.c\n",
    "#include <stdio.h>\n",
    "#include <sys/utsname.h>\n",
    "#include <mpi.h>\n",
    "int main(int argc, char *argv[]){\n",
    "  MPI_Init(&argc, &argv);\n",
    "  struct utsname uts;\n",
    "  uname (&uts);\n",
    "  printf(\"My process is on node %s.\\n\", uts.nodename);\n",
    "  MPI_Finalize();\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My process is on node localhost.localdomain.\r\n",
      "My process is on node localhost.localdomain.\r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/first.c -o ~/first\n",
    "!mpirun -np 2 ~/first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> The working of MPI in a nutshell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- All processes are launched at the beginning of the program execution\n",
    "    - The number of processes are user-speficied\n",
    "    - Typically, this number is matched to the total number of cores available across the entire cluster\n",
    "- All processes have their own memory space and have access to the same source codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Basic parameters available to individual processes: **\n",
    "```\n",
    "MPI.COMM_WORLD\n",
    "MPI_Comm_rank()\n",
    "MPI_Comm_size()\n",
    "MPI_Get_processor_name()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- MPI defines **communicator** groups for point-to-point and collective communications\n",
    "    - Unique IDs (**rank**) are defined for individual processes within a communicator group\n",
    "    - Communications are performed based on these IDs\n",
    "    - Default **global communication** (MPI_COMM_WORLD) contains all processes\n",
    "    - For $N$ processes, ranks go from $0$ to $N-1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/hello.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/hello.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "  int size;\n",
    "  int my_rank; \n",
    "  char proc_name[MPI_MAX_PROCESSOR_NAME];\n",
    "  int proc_name_len;\n",
    "    \n",
    "  /* Initialize the MPI environment */\n",
    "  MPI_Init(&argc, &argv);\n",
    "  \n",
    "  /* Get the number of processes */\n",
    "  MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "  /* Get the rank of the process */\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "\n",
    "  /* Get the name of the processor */\n",
    "  MPI_Get_processor_name(proc_name, &proc_name_len);\n",
    "\n",
    "  /* Print off a hello world message */\n",
    "  printf(\"Hello world from processor %s, rank %d out of %d processes\\n\",\n",
    "           proc_name, my_rank, size);\n",
    "\n",
    "  /* Finalize the MPI environment. */\n",
    "  MPI_Finalize();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world from processor localhost.localdomain, rank 0 out of 2 processes\r\n",
      "Hello world from processor localhost.localdomain, rank 1 out of 2 processes\r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/hello.c -o ~/hello\n",
    "!mpirun -np 2 ~/hello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Important\n",
    "\n",
    "On many VM, you might not have enough physical cores located to the VM in VirtualBox. To enable the simulation of multiple processes, you need to add `--map-by core:OVERSUBSCRIBE` to your `mpirun` commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "There are not enough slots available in the system to satisfy the 8 slots\n",
      "that were requested by the application:\n",
      "  /home/lngo/hello\n",
      "\n",
      "Either request fewer slots for your application, or make more slots available\n",
      "for use.\n",
      "--------------------------------------------------------------------------\n",
      "Hello world from processor localhost.localdomain, rank 3 out of 8 processes\n",
      "Hello world from processor localhost.localdomain, rank 6 out of 8 processes\n",
      "Hello world from processor localhost.localdomain, rank 7 out of 8 processes\n",
      "Hello world from processor localhost.localdomain, rank 0 out of 8 processes\n",
      "Hello world from processor localhost.localdomain, rank 1 out of 8 processes\n",
      "Hello world from processor localhost.localdomain, rank 4 out of 8 processes\n",
      "Hello world from processor localhost.localdomain, rank 5 out of 8 processes\n",
      "Hello world from processor localhost.localdomain, rank 2 out of 8 processes\n"
     ]
    }
   ],
   "source": [
    "!mpirun -np 8 ~/hello\n",
    "!mpirun -np 8 --map-by core:OVERSUBSCRIBE ~/hello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Ranks are used to enforce execution/exclusion of code segments within the original source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/evenodd.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/evenodd.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "  int my_rank; \n",
    "    \n",
    "  /* Initialize the MPI environment */\n",
    "  MPI_Init(&argc, &argv);\n",
    "\n",
    "  /* Get the rank of the process */\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "\n",
    "  if (my_rank % 2 == 0) {\n",
    "    printf (\"Process %d is even \\n\", my_rank);\n",
    "  } else {\n",
    "    printf (\"Process %d is odd \\n\", my_rank);\n",
    "  }\n",
    "  MPI_Finalize();\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 1 is odd \r\n",
      "Process 2 is even \r\n",
      "Process 0 is even \r\n",
      "Process 3 is odd \r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/evenodd.c -o ~/evenodd\n",
    "!mpirun -np 4 ~/evenodd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Ranks and size are used means to calculate and distributed workload (data) among the processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/rank_size.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/rank_size.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "  int size;\n",
    "  int my_rank; \n",
    "  int A[16] = {2,13,4,3,5,1,0,12,10,8,7,9,11,6,15,14};\n",
    "  int i;\n",
    "    \n",
    "  MPI_Init(&argc, &argv);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "\n",
    "  for (i = 0; i < 16; i++){\n",
    "    if (i % size == my_rank){\n",
    "      printf (\"Process %d has elements %d at index %d \\n\",\n",
    "               my_rank, A[i], i);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  /* Finalize the MPI environment. */\n",
    "  MPI_Finalize();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 2 has elements 4 at index 2 \r\n",
      "Process 2 has elements 0 at index 6 \r\n",
      "Process 2 has elements 7 at index 10 \r\n",
      "Process 2 has elements 15 at index 14 \r\n",
      "Process 3 has elements 3 at index 3 \r\n",
      "Process 3 has elements 12 at index 7 \r\n",
      "Process 3 has elements 9 at index 11 \r\n",
      "Process 3 has elements 14 at index 15 \r\n",
      "Process 0 has elements 2 at index 0 \r\n",
      "Process 0 has elements 5 at index 4 \r\n",
      "Process 0 has elements 10 at index 8 \r\n",
      "Process 0 has elements 11 at index 12 \r\n",
      "Process 1 has elements 13 at index 1 \r\n",
      "Process 1 has elements 1 at index 5 \r\n",
      "Process 1 has elements 8 at index 9 \r\n",
      "Process 1 has elements 6 at index 13 \r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/rank_size.c -o ~/rank_size\n",
    "!mpirun -np 4 ~/rank_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Individual processes rely on communication (message passing) to enforce workflow\n",
    "    - Point-to-point Communication\n",
    "    - Collective Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Point-to-Point: Send and Receive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Original MPI C Syntax: MPI_Send**\n",
    "```\n",
    "int MPI_Send(void *buf, \n",
    "\tint count, \n",
    "\tMPI_Datatype datatype, \n",
    "\tint dest, \n",
    "\tint tag, \n",
    "\tMPI_Comm comm)\n",
    "```\n",
    "\n",
    "- MPI_Datatype may be MPI_BYTE, MPI_PACKED, MPI_CHAR, MPI_SHORT, MPI_INT, MPI_LONG, MPI_FLOAT, MPI_DOUBLE, MPI_LONG_DOUBLE, MPI_UNSIGNED_CHAR\n",
    "- *dest* is the rank of the process the message is sent to\n",
    "- *tag* is an integer identify the message. Programmer is responsible for managing tag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Original MPI C Syntax: MPI_Recv**\n",
    "```\n",
    "int MPI_Recv(\n",
    "\tvoid *buf, \n",
    "\tint count, \n",
    "\tMPI_Datatype datatype, \n",
    "\tint source, \n",
    "\tint tag, \n",
    "\tMPI_Comm comm,\n",
    "\tMPI_Status *status)\n",
    "```\n",
    "\n",
    "- MPI_Datatype may be MPI_BYTE, MPI_PACKED, MPI_CHAR, MPI_SHORT, MPI_INT, MPI_LONG, MPI_FLOAT, MPI_DOUBLE, MPI_LONG_DOUBLE, MPI_UNSIGNED_CHAR\n",
    "- *source* is the rank of the process from which the message was sent.\n",
    "- *tag* is an integer identify the message. MPI_Recv will only place data in the buffer if the tag from MPI_Send matches. The constant MPI_ANY_TAG may be used when the source tag is unknown or not important. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "We want to write an MPI program that exchange the ranks of two processes, 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing codes/openmpi/send_recv.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/send_recv.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "#include <string.h>\n",
    "\n",
    "int main(int argc, char** argv) \n",
    "{\n",
    "  int my_rank;       \n",
    "  int size;             \n",
    "  int tag=0;\n",
    "  int buf,i;\n",
    "  int des1,des2;\n",
    "  MPI_Status status;\n",
    "\n",
    "  MPI_Init(&argc, &argv);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "  /*  set up data */\n",
    "  buf = my_rank; \n",
    "\n",
    "  printf(\"Process %2d has original value %2d \\n\",my_rank,buf);\n",
    "    \n",
    "  if (my_rank == 0){\n",
    "    MPI_Send(&buf,1,MPI_INT,1,tag,MPI_COMM_WORLD);\n",
    "    MPI_Recv(&buf,1,MPI_INT,1,tag,MPI_COMM_WORLD,&status);\n",
    "  }\n",
    "  \n",
    "  if (my_rank == 1){\n",
    "    MPI_Recv(&buf,1,MPI_INT,0,tag,MPI_COMM_WORLD,&status);\n",
    "    MPI_Send(&buf,1,MPI_INT,0,tag,MPI_COMM_WORLD);  \n",
    "  }    \n",
    "  printf(\"Process %2d now has value %2d\\n\",my_rank,buf);\n",
    "\n",
    "  MPI_Finalize();\n",
    "} /* end main */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process  0 has original value  0 \r\n",
      "Process  0 now has value  0\r\n",
      "Process  1 has original value  1 \r\n",
      "Process  1 now has value  0\r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/send_recv.c -o ~/send_recv\n",
    "!mpirun -np 2 ~/send_recv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- What went wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /home/lngo/send_recv_fixed.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/send_recv_fixed.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "#include <string.h>\n",
    "\n",
    "int main(int argc, char** argv) \n",
    "{\n",
    "  int my_rank;       \n",
    "  int size;             \n",
    "  int tag=0;\n",
    "  int buf,i;\n",
    "  int des1,des2;\n",
    "  MPI_Status status;\n",
    "\n",
    "  MPI_Init(&argc, &argv);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "  /*  set up data */\n",
    "  buf = my_rank; \n",
    "\n",
    "  printf(\"Process %2d has original value %2d \\n\",my_rank,buf);\n",
    "    \n",
    "  if (my_rank == 0){\n",
    "    MPI_Send(&buf,1,MPI_INT,1,tag,MPI_COMM_WORLD);\n",
    "    MPI_Recv(&buf,1,MPI_INT,1,tag,MPI_COMM_WORLD,&status);\n",
    "  }\n",
    "  \n",
    "  if (my_rank == 1){\n",
    "    MPI_Recv(&buf,1,MPI_INT,0,tag,MPI_COMM_WORLD,&status);\n",
    "    MPI_Send(&buf,1,MPI_INT,0,tag,MPI_COMM_WORLD);  \n",
    "  }    \n",
    "  printf(\"Process %2d now has value %2d\\n\",my_rank,buf);\n",
    "\n",
    "  MPI_Finalize();\n",
    "} /* end main */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process  0 has original value  0 \r\n",
      "Process  0 now has value  0\r\n",
      "Process  1 has original value  1 \r\n",
      "Process  1 now has value  0\r\n"
     ]
    }
   ],
   "source": [
    "!mpicc ~/send_recv_fixed.c -o ~/send_recv_fixed\n",
    "!mpirun -np 2 ~/send_recv_fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do we do point-to-point communication at scale?\n",
    "- Rely on rank and size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/multi_send_recv.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/multi_send_recv.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "#include <string.h>\n",
    "\n",
    "int main(int argc, char** argv) \n",
    "{\n",
    "  int my_rank;       \n",
    "  int size;             \n",
    "  int tag=0;\n",
    "  int buf,i;\n",
    "  int des1,des2;\n",
    "  MPI_Status status;\n",
    "\n",
    "  MPI_Init(&argc, &argv);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "  /*  set up data */\n",
    "  buf = my_rank; \n",
    "\n",
    "  printf(\"Process %2d has original value %2d \\n\",my_rank,buf);\n",
    "    \n",
    "  /* set up source and destination */\n",
    "  des1 = (my_rank + 1) % size;\n",
    "  des2 = (my_rank + size - 1) % size;\n",
    "\n",
    "  /* shift the data n/2 steps */\n",
    "  for (i = 0; i < size/2; i++){\n",
    "    MPI_Send(&buf,1,MPI_INT,des1,tag,MPI_COMM_WORLD);\n",
    "    MPI_Recv(&buf,1,MPI_INT,MPI_ANY_SOURCE,tag,MPI_COMM_WORLD,&status);\n",
    "  }\n",
    "\n",
    "  MPI_Send(&buf,1,MPI_INT,des2,tag,MPI_COMM_WORLD);\n",
    "  MPI_Recv(&buf,1,MPI_INT,MPI_ANY_SOURCE,tag,MPI_COMM_WORLD,&status);\n",
    "  \n",
    "  MPI_Barrier(MPI_COMM_WORLD);\n",
    "  printf(\"Process %2d now has value %2d\\n\",my_rank,buf);\n",
    "\n",
    "  /* Shut down MPI */\n",
    "  MPI_Finalize();\n",
    "\n",
    "} /* end main */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process  0 has original value  0 \r\n",
      "Process  0 now has value  2\r\n",
      "Process  1 has original value  1 \r\n",
      "Process  1 now has value  0\r\n",
      "Process  2 has original value  2 \r\n",
      "Process  2 now has value  1\r\n",
      "Process  3 has original value  3 \r\n",
      "Process  3 now has value  3\r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/multi_send_recv.c -o ~/multi_send_recv\n",
    "!mpirun -np 4 ~/multi_send_recv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Blocking risks**\n",
    "- Send data larger than available network buffer (Blocking send)\n",
    "- Lost data (or missing sender) leading to receiver hanging indefinitely (Blocking receive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/deadlock_send_recv.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/deadlock_send_recv.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "#include <string.h>\n",
    "\n",
    "int main(int argc, char* argv[]) \n",
    "{\n",
    "  int my_rank;       /* rank of process     */\n",
    "  int size;             /* number of processes */\n",
    "  int source;        /* rank of sender      */\n",
    "  int dest;          /* rank of receiver    */\n",
    "\n",
    "  int tag=0;         /* tag for messages    */\n",
    "  char message[100]; /* storage for message */\n",
    "  MPI_Status status; /* return status for receive */\n",
    "\n",
    "  MPI_Init(&argc, &argv);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "  fprintf(stderr,\"I am here!  ID = %d\\n\", my_rank);\n",
    "  sprintf(message, \"Greetings from process %d!\", my_rank);\n",
    "\n",
    "  if (my_rank == 0) {\n",
    "    dest = 1;\n",
    "    MPI_Recv(message, 100, MPI_CHAR, dest, tag, MPI_COMM_WORLD, &status);\n",
    "    MPI_Send(message, strlen(message)+1, MPI_CHAR, dest, tag, MPI_COMM_WORLD);\n",
    "    printf(\"Process 0 printing:  %s\\n\", message);\n",
    "  }\n",
    "  else { \n",
    "    /* my rank == 1 */\n",
    "    dest = 0;\n",
    "    MPI_Recv(message, 100, MPI_CHAR, dest, tag, MPI_COMM_WORLD, &status);\n",
    "    MPI_Send(message, strlen(message)+1, MPI_CHAR, dest, tag, MPI_COMM_WORLD);\n",
    "    printf(\"Process 1 printing:  %s\\n\", message);\n",
    "  }\n",
    "  \n",
    "  MPI_Finalize();\n",
    "} /* end main */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am here!  ID = 0\n",
      "I am here!  ID = 1\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/deadlock_send_recv.c -o ~/deadlock_send_recv\n",
    "!mpirun -np 2 ~/deadlock_send_recv\n",
    "\n",
    "# The [*] is indicative of a running notebook shell, and if it does not turn into a number, \n",
    "# it means the cell is hanged (deadlocked by MPI).\n",
    "# To escape a hanged cell, click the Square (Stop) button in the tool bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To correct the above error, we need to change the order of the MPI_Recv and MPI_Send in the one of the communication code block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Collective Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Must involve ALL processes within the scope of a communicator\n",
    "- Unexpected behavior, including programming failure, if even one process does not participate\n",
    "- Types of collective communications:\n",
    "    - Synchronization: barrier\n",
    "    - Data movement: broadcast, scatter/gather\n",
    "    - Collective computation (aggregate data to perform computation): Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/05/mpi-collective.png\" width=\"700\"/> \n",
    "<sub> *https://computing.llnl.gov/tutorials/mpi/* </sub>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```\n",
    "int MPI_Bcast(\n",
    "\tvoid *buf, \n",
    "\tint count, \n",
    "\tMPI_Datatype datatype, \n",
    "\tint root, \n",
    "\tMPI_Comm comm);\n",
    "```\n",
    "- Donâ€™t need to specify a TAG or DESTINATION\n",
    "- Must specify the SENDER (root)\n",
    "- Blocking call for all processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/bcast.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/bcast.c\n",
    "#include <stdio.h>\n",
    "#include <mpi.h>\n",
    "\n",
    "int main(int argc, char* argv[]) \n",
    "{\n",
    "  int my_rank;       \n",
    "  int size;\n",
    "  int value;\n",
    "\n",
    "  MPI_Init(&argc, &argv);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank); \n",
    "  \n",
    "  value = my_rank;\n",
    "  printf(\"process %d: Before MPI_Bcast, value is %d\\n\", my_rank, value); \n",
    "\n",
    "  MPI_Bcast(&value, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "  printf(\"process %d: After MPI_Bcast, value is %d\\n\", my_rank, value);\n",
    "\n",
    "  MPI_Finalize();\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 0: Before MPI_Bcast, value is 0\r\n",
      "process 0: After MPI_Bcast, value is 0\r\n",
      "process 1: Before MPI_Bcast, value is 1\r\n",
      "process 1: After MPI_Bcast, value is 0\r\n",
      "process 2: Before MPI_Bcast, value is 2\r\n",
      "process 2: After MPI_Bcast, value is 0\r\n",
      "process 3: Before MPI_Bcast, value is 3\r\n",
      "process 3: After MPI_Bcast, value is 0\r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/bcast.c -o ~/bcast\n",
    "!mpirun -np 4 ~/bcast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Original MPI C Syntax: MPI_Scatter**\n",
    "```\n",
    "int MPI_Scatter(\n",
    "\tvoid *sendbuf, \n",
    "\tint sendcount, \n",
    "\tMPI_Datatype sendtype, \n",
    "\tvoid *recvbuf,\n",
    "\tint recvcnt,\n",
    "\tMPI_Datatype recvtype,\n",
    "\tint root, \n",
    "\tMPI_Comm comm);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing codes/openmpi/scatter.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/scatter.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "  int size;\n",
    "  int my_rank; \n",
    "  int sendbuf[16] = {2,13,4,3,5,1,0,12,10,8,7,9,11,6,15,14};\n",
    "  int recvbuf[4];\n",
    "  int i;\n",
    "    \n",
    "  MPI_Init(&argc, &argv);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "\n",
    "  MPI_Scatter(&sendbuf, 4, MPI_INT, &recvbuf, 4, MPI_INT, 0, MPI_COMM_WORLD); \n",
    "  for (i = 0; i < 4; i++){\n",
    "    printf (\"Process %d has element %d at index %d in its recvbuf \\n\",\n",
    "               my_rank, recvbuf[i], i);\n",
    "  }\n",
    "\n",
    "  /* Finalize the MPI environment. */\n",
    "  MPI_Finalize();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 0 has element 2 at index 0 in its recvbuf \r\n",
      "Process 0 has element 13 at index 1 in its recvbuf \r\n",
      "Process 0 has element 4 at index 2 in its recvbuf \r\n",
      "Process 0 has element 3 at index 3 in its recvbuf \r\n",
      "Process 1 has element 5 at index 0 in its recvbuf \r\n",
      "Process 1 has element 1 at index 1 in its recvbuf \r\n",
      "Process 1 has element 0 at index 2 in its recvbuf \r\n",
      "Process 1 has element 12 at index 3 in its recvbuf \r\n",
      "Process 2 has element 10 at index 0 in its recvbuf \r\n",
      "Process 2 has element 8 at index 1 in its recvbuf \r\n",
      "Process 2 has element 7 at index 2 in its recvbuf \r\n",
      "Process 2 has element 9 at index 3 in its recvbuf \r\n",
      "Process 3 has element 11 at index 0 in its recvbuf \r\n",
      "Process 3 has element 6 at index 1 in its recvbuf \r\n",
      "Process 3 has element 15 at index 2 in its recvbuf \r\n",
      "Process 3 has element 14 at index 3 in its recvbuf \r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/scatter.c -o ~/scatter\n",
    "!mpirun -np 4 ~/scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Original MPI C Syntax: MPI_Gather**\n",
    "```\n",
    "int MPI_Gather(\n",
    "\tvoid *sendbuff, \n",
    "\tint sendcount, \n",
    "\tMPI_Datatype sendtype, \n",
    "\tvoid *recvbuff,\n",
    "\tint recvcnt,\n",
    "\tMPI_Datatype recvtype,\n",
    "\tint root, \n",
    "\tMPI_Comm comm);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codes/openmpi/gather.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/gather.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "  int size;\n",
    "  int my_rank; \n",
    "  int sendbuf[2];\n",
    "  int recvbuf[8] = {-1,-1,-1,-1,-1,-1,-1,-1};\n",
    "  int i;\n",
    "    \n",
    "  MPI_Init(&argc, &argv);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "\n",
    "  for (i = 0; i < 2; i++){\n",
    "    sendbuf[i] = my_rank;\n",
    "  }\n",
    "  MPI_Gather(&sendbuf, 2, MPI_INT, &recvbuf, 2, MPI_INT, 0, MPI_COMM_WORLD); \n",
    "  for (i = 0; i < 8; i++){\n",
    "    printf (\"Process %d has element %d at index %d in its recvbuf \\n\",\n",
    "               my_rank, recvbuf[i], i);\n",
    "  }\n",
    "\n",
    "  /* Finalize the MPI environment. */\n",
    "  MPI_Finalize();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 2 has element -1 at index 0 in its recvbuf \r\n",
      "Process 2 has element -1 at index 1 in its recvbuf \r\n",
      "Process 2 has element -1 at index 2 in its recvbuf \r\n",
      "Process 2 has element -1 at index 3 in its recvbuf \r\n",
      "Process 2 has element -1 at index 4 in its recvbuf \r\n",
      "Process 2 has element -1 at index 5 in its recvbuf \r\n",
      "Process 2 has element -1 at index 6 in its recvbuf \r\n",
      "Process 2 has element -1 at index 7 in its recvbuf \r\n",
      "Process 3 has element -1 at index 0 in its recvbuf \r\n",
      "Process 3 has element -1 at index 1 in its recvbuf \r\n",
      "Process 3 has element -1 at index 2 in its recvbuf \r\n",
      "Process 3 has element -1 at index 3 in its recvbuf \r\n",
      "Process 3 has element -1 at index 4 in its recvbuf \r\n",
      "Process 3 has element -1 at index 5 in its recvbuf \r\n",
      "Process 3 has element -1 at index 6 in its recvbuf \r\n",
      "Process 3 has element -1 at index 7 in its recvbuf \r\n",
      "Process 0 has element 0 at index 0 in its recvbuf \r\n",
      "Process 0 has element 0 at index 1 in its recvbuf \r\n",
      "Process 0 has element 1 at index 2 in its recvbuf \r\n",
      "Process 0 has element 1 at index 3 in its recvbuf \r\n",
      "Process 0 has element 2 at index 4 in its recvbuf \r\n",
      "Process 0 has element 2 at index 5 in its recvbuf \r\n",
      "Process 0 has element 3 at index 6 in its recvbuf \r\n",
      "Process 0 has element 3 at index 7 in its recvbuf \r\n",
      "Process 1 has element -1 at index 0 in its recvbuf \r\n",
      "Process 1 has element -1 at index 1 in its recvbuf \r\n",
      "Process 1 has element -1 at index 2 in its recvbuf \r\n",
      "Process 1 has element -1 at index 3 in its recvbuf \r\n",
      "Process 1 has element -1 at index 4 in its recvbuf \r\n",
      "Process 1 has element -1 at index 5 in its recvbuf \r\n",
      "Process 1 has element -1 at index 6 in its recvbuf \r\n",
      "Process 1 has element -1 at index 7 in its recvbuf \r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/gather.c -o ~/gather\n",
    "!mpirun -np 4 ~/gather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Original MPI C Syntax: MPI_Reduce**\n",
    "```\n",
    "int MPI_Reduce(\n",
    "\tvoid *sendbuf, \n",
    "\tvoid *recvbuff,\n",
    "\tint count, \n",
    "\tMPI_Datatype datatype, \n",
    "\tMPI_OP op,\n",
    "\tint root, \n",
    "\tMPI_Comm comm);\n",
    "```\n",
    "- MPI_Op may be MPI_MIN, MPI_MAX, MPI_SUM, MPI_PROD (twelve total)\n",
    "- Programmer may add operations, must be commutative and associative\n",
    "- If count > 1, then operation is performed element-wise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing codes/openmpi/reduce.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile codes/openmpi/reduce.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "  int size;\n",
    "  int my_rank; \n",
    "  int rank_sum;\n",
    "  int i;\n",
    "    \n",
    "  MPI_Init(&argc, &argv);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "  \n",
    "  rank_sum = my_rank;\n",
    "\n",
    "  MPI_Reduce(&my_rank, &rank_sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD); \n",
    "  printf (\"The total sum of all ranks at process %d is %d \\n\", my_rank, rank_sum);\n",
    "\n",
    "  /* Finalize the MPI environment. */\n",
    "  MPI_Finalize();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total sum of all ranks at process 0 is 6 \r\n",
      "The total sum of all ranks at process 1 is 1 \r\n",
      "The total sum of all ranks at process 2 is 2 \r\n",
      "The total sum of all ranks at process 3 is 3 \r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/reduce.c -o ~/reduce\n",
    "!mpirun -np 4 ~/reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total sum of all ranks at process 3 is 3 \r\n",
      "The total sum of all ranks at process 5 is 5 \r\n",
      "The total sum of all ranks at process 1 is 1 \r\n",
      "The total sum of all ranks at process 2 is 2 \r\n",
      "The total sum of all ranks at process 6 is 6 \r\n",
      "The total sum of all ranks at process 7 is 7 \r\n",
      "The total sum of all ranks at process 0 is 28 \r\n",
      "The total sum of all ranks at process 4 is 4 \r\n"
     ]
    }
   ],
   "source": [
    "!mpicc codes/openmpi/reduce.c -o ~/reduce\n",
    "!mpirun -np 8 --map-by core:OVERSUBSCRIBE ~/reduce"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
